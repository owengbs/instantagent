#!/usr/bin/env python3
"""
Qwenæµå¼å¯¹è¯æµ‹è¯•è„šæœ¬
éªŒè¯é˜¿é‡Œäº‘ç™¾ç‚¼APIçš„æµå¼åŠŸèƒ½
"""
import os
import sys
import asyncio
from openai import AsyncOpenAI

# è®¾ç½®APIé…ç½®
API_KEY = "sk-ff980442223b45868202e5cb35724bb1"
BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"
MODEL = "qwen-plus"

async def test_qwen_streaming():
    """æµ‹è¯•Qwenæµå¼å¯¹è¯"""
    print("ğŸ§ª æµ‹è¯•Qwenæµå¼å¯¹è¯...")
    print("=" * 50)
    
    client = AsyncOpenAI(
        api_key=API_KEY,
        base_url=BASE_URL
    )
    
    test_questions = [
        "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
        "è¯·è¯¦ç»†è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯è‚¡ç¥¨äº¤æ˜“ï¼ŒåŒ…æ‹¬åŸºæœ¬æ¦‚å¿µå’Œæµç¨‹",
        "Hello, can you speak Chinese and English? è¯·ç”¨ä¸­è‹±æ–‡å›ç­”è¿™ä¸ªé—®é¢˜ã€‚"
    ]
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n--- æµ‹è¯• {i}: {question} ---")
        
        try:
            # è°ƒç”¨æµå¼API
            stream = await client.chat.completions.create(
                model=MODEL,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‚¡ç¥¨äº¤æ˜“å®¢æœåŠ©æ‰‹ã€‚"},
                    {"role": "user", "content": question}
                ],
                stream=True,
                temperature=0.7,
                max_tokens=1024
            )
            
            full_content = ""
            chunk_count = 0
            
            print("ğŸ“ æµå¼è¾“å‡ºå†…å®¹:")
            async for chunk in stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_content += content
                    chunk_count += 1
                    print(content, end="", flush=True)
            
            print(f"\n\nâœ… æµå¼å›å¤å®Œæˆ:")
            print(f"   - ç‰‡æ®µæ•°é‡: {chunk_count}")
            print(f"   - æ€»é•¿åº¦: {len(full_content)}")
            print(f"   - å®Œæ•´å†…å®¹: {full_content[:100]}...")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        
        print("\n" + "-" * 50)
        await asyncio.sleep(1)

async def test_simple_request():
    """æµ‹è¯•ç®€å•çš„éæµå¼è¯·æ±‚"""
    print("\nğŸ” æµ‹è¯•ç®€å•è¯·æ±‚...")
    
    client = AsyncOpenAI(
        api_key=API_KEY,
        base_url=BASE_URL
    )
    
    try:
        response = await client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "ä½ æ˜¯è°ï¼Ÿè¯·ç®€å•å›ç­”ã€‚"}
            ],
            temperature=0.7,
            max_tokens=256
        )
        
        content = response.choices[0].message.content
        print(f"âœ… ç®€å•è¯·æ±‚æˆåŠŸ: {content}")
        
    except Exception as e:
        print(f"âŒ ç®€å•è¯·æ±‚å¤±è´¥: {e}")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Qwenæµå¼å¯¹è¯æµ‹è¯•å·¥å…·")
    print(f"ğŸ”‘ API Key: {API_KEY[:10]}...")
    print(f"ğŸ“¡ Base URL: {BASE_URL}")
    print(f"ğŸ¤– Model: {MODEL}")
    print("=" * 60)
    
    # æµ‹è¯•ç®€å•è¯·æ±‚
    await test_simple_request()
    
    # æµ‹è¯•æµå¼å¯¹è¯
    await test_qwen_streaming()
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•è¢«ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc() 