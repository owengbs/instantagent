#!/usr/bin/env python3
"""
æ–‡æœ¬ä¼˜åŒ–æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¤§æ¨¡å‹è¾“å‡ºæ–‡æœ¬çš„TTSä¼˜åŒ–æ•ˆæœ
"""
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.text_cleaner import text_cleaner

def demo_text_optimization():
    """æ¼”ç¤ºæ–‡æœ¬ä¼˜åŒ–æ•ˆæœ"""
    print("ğŸ¤ TTSæ–‡æœ¬ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿå¤§æ¨¡å‹çš„å®é™…è¾“å‡º
    original_text = """æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„è‚¡ç¥¨äº¤æ˜“åŠ©æ‰‹ ğŸ˜Š

å…³äºæ‚¨è¯¢é—®çš„å¼€æˆ·æµç¨‹ï¼Œæˆ‘æ¥ä¸ºæ‚¨è¯¦ç»†ä»‹ç»ï¼š

## å¼€æˆ·æ­¥éª¤ï¼š
1. **é€‰æ‹©è¯åˆ¸å…¬å¸** - æˆ‘æ¨èæ‚¨é€‰æ‹©å¤§å‹åˆ¸å•†ï¼Œæ¯”å¦‚ä¸­ä¿¡è¯åˆ¸ã€åæ³°è¯åˆ¸ç­‰ï¼Œè¿™äº›åˆ¸å•†æœåŠ¡æ¯”è¾ƒå®Œå–„
2. **å‡†å¤‡èº«ä»½è¯** - è¯·ç¡®ä¿æ‚¨çš„èº«ä»½è¯åœ¨æœ‰æ•ˆæœŸå†…ï¼Œè¿™æ˜¯å¼€æˆ·çš„å¿…å¤‡ææ–™
3. **ä¸‹è½½APP** - è¯·ä»å®˜æ–¹æ¸ é“ä¸‹è½½äº¤æ˜“APPï¼Œé¿å…ä½¿ç”¨ç¬¬ä¸‰æ–¹è½¯ä»¶
4. **åœ¨çº¿å¼€æˆ·** - æŒ‰ç…§APPæç¤ºå®Œæˆå¼€æˆ·æ“ä½œï¼Œæ•´ä¸ªè¿‡ç¨‹å¤§çº¦éœ€è¦10åˆ†é’Ÿ

## æ³¨æ„äº‹é¡¹ï¼š
âš ï¸ è¯·ç¡®ä¿ç½‘ç»œç¯å¢ƒå®‰å…¨ï¼Œä¸è¦åœ¨å…¬å…±WiFiä¸‹æ“ä½œ
ğŸ’¡ å»ºè®®åœ¨è¥ä¸šæ—¶é—´ï¼ˆ9:00-15:00ï¼‰è¿›è¡Œæ“ä½œ
ğŸ“ å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥è”ç³»å®¢æœçƒ­çº¿

## åç»­å»ºè®®ï¼š
â€¢ å¼€æˆ·æˆåŠŸåï¼Œå»ºè®®å…ˆå­¦ä¹ åŸºç¡€çŸ¥è¯†
â€¢ å¯ä»¥å…ˆç”¨å°èµ„é‡‘ç»ƒä¹ ï¼Œç†Ÿæ‚‰æ“ä½œæµç¨‹
â€¢ æŠ•èµ„æœ‰é£é™©ï¼Œè¯·è°¨æ…æ“ä½œ

å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹æ‚¨æœ‰å¸®åŠ©ï¼å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å¯ä»¥é—®æˆ‘ ğŸ‰"""
    
    print("ğŸ“ åŸå§‹å¤§æ¨¡å‹è¾“å‡º:")
    print("-" * 40)
    print(original_text)
    print("-" * 40)
    print(f"ğŸ“Š åŸå§‹é•¿åº¦: {len(original_text)} å­—ç¬¦")
    
    print("\nğŸ§¹ æ–‡æœ¬æ¸…ç†è¿‡ç¨‹:")
    print("-" * 40)
    
    # é€æ­¥å±•ç¤ºæ¸…ç†è¿‡ç¨‹
    steps = [
        ("ç§»é™¤è¡¨æƒ…ç¬¦å·", r'[ğŸ˜€-ğŸ™ğŸŒ€-ğŸ—¿ğŸ˜€-ğŸ˜¿ğŸš€-ğŸ›¿âš¡-âš¿ğŸ’¡-ğŸ’¿ğŸ“±-ğŸ“¿ğŸµ-ğŸ¿ğŸ€-ğŸ¿ğŸŒ-ğŸŒ¿ğŸ€-ğŸ¿]'),
        ("ç§»é™¤æ ‡é¢˜æ ¼å¼", r'^#{1,6}\s+'),
        ("ç§»é™¤åˆ—è¡¨æ ¼å¼", r'^\d+\.\s+'),
        ("ç§»é™¤é¡¹ç›®ç¬¦å·", r'^[â€¢Â·]\s+'),
        ("ç§»é™¤ç‰¹æ®Šç¬¦å·", r'[ã€ã€‘ã€Œã€ã€ã€ã€ˆã€‰ã€Šã€‹ï¼ˆï¼‰ï¼»ï¼½ï½›ï½]'),
        ("å¤„ç†é‡å¤æ ‡ç‚¹", r'[ï¼ï¼Ÿã€‚ï¼Œï¼›ï¼š]{2,}'),
        ("æ¸…ç†å¤šä½™ç©ºæ ¼", r'\s+'),
    ]
    
    current_text = original_text
    for step_name, pattern in steps:
        import re
        if pattern.startswith('^'):
            # å¤šè¡Œæ¨¡å¼
            current_text = re.sub(pattern, '', current_text, flags=re.MULTILINE)
        else:
            current_text = re.sub(pattern, '', current_text)
        
        print(f"âœ… {step_name}: {len(current_text)} å­—ç¬¦")
    
    print("-" * 40)
    
    # æœ€ç»ˆTTSä¼˜åŒ–
    final_text = text_cleaner.clean_for_tts(original_text)
    
    print("\nğŸ¤ TTSä¼˜åŒ–åæ–‡æœ¬:")
    print("-" * 40)
    print(final_text)
    print("-" * 40)
    print(f"ğŸ“Š ä¼˜åŒ–åé•¿åº¦: {len(final_text)} å­—ç¬¦")
    
    # ç»Ÿè®¡ä¼˜åŒ–æ•ˆæœ
    reduction = len(original_text) - len(final_text)
    reduction_rate = (reduction / len(original_text)) * 100
    
    print(f"\nğŸ“ˆ ä¼˜åŒ–æ•ˆæœ:")
    print(f"   - å­—ç¬¦å‡å°‘: {reduction} ä¸ª ({reduction_rate:.1f}%)")
    print(f"   - æ¸…ç†æ•ˆæœ: {'âœ… ä¼˜ç§€' if reduction_rate > 20 else 'âœ… è‰¯å¥½' if reduction_rate > 10 else 'âš ï¸ ä¸€èˆ¬'}")
    
    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é—®é¢˜å­—ç¬¦
    problematic_chars = []
    for char in final_text:
        if ord(char) > 127 and char not in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š':
            problematic_chars.append(char)
    
    if problematic_chars:
        print(f"   - âš ï¸ å‰©ä½™é—®é¢˜å­—ç¬¦: {set(problematic_chars)}")
    else:
        print(f"   - âœ… æ— é—®é¢˜å­—ç¬¦ï¼Œå®Œå…¨é€‚åˆTTS")
    
    # å¥å­åˆ†å‰²æ¼”ç¤º
    print(f"\nğŸ“‹ å¥å­åˆ†å‰²ç»“æœ:")
    sentences = text_cleaner.split_into_sentences(final_text)
    for i, sentence in enumerate(sentences, 1):
        print(f"   {i}. {sentence}")
    
    print(f"\nâœ… å…±åˆ†å‰²å‡º {len(sentences)} ä¸ªå¥å­ï¼Œå¹³å‡é•¿åº¦: {sum(len(s) for s in sentences) / len(sentences):.1f} å­—ç¬¦")

def demo_comparison():
    """å¯¹æ¯”æ¼”ç¤º"""
    print("\nğŸ”„ å¯¹æ¯”æ¼”ç¤º")
    print("=" * 60)
    
    test_cases = [
        {
            "name": "ç®€å•å¯¹è¯",
            "original": "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„è‚¡ç¥¨äº¤æ˜“åŠ©æ‰‹ ğŸ˜Šï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼",
            "description": "åŒ…å«è¡¨æƒ…ç¬¦å·çš„ç®€å•å¯¹è¯"
        },
        {
            "name": "åˆ—è¡¨è¯´æ˜",
            "original": """å¼€æˆ·æµç¨‹ï¼š
1. é€‰æ‹©è¯åˆ¸å…¬å¸
2. å‡†å¤‡èº«ä»½è¯
3. ä¸‹è½½APP
4. åœ¨çº¿å¼€æˆ·""",
            "description": "åŒ…å«åˆ—è¡¨æ ¼å¼çš„è¯´æ˜"
        },
        {
            "name": "å¤æ‚æ ¼å¼",
            "original": """# é‡è¦æç¤º âš ï¸

## æŠ•èµ„é£é™©ï¼š
â€¢ è‚¡ç¥¨ä»·æ ¼å¯èƒ½ä¸‹è·Œ ğŸ“‰
â€¢ å¯èƒ½æŸå¤±æœ¬é‡‘ ğŸ’¸
â€¢ éœ€è¦æ‰¿æ‹…é£é™© âš¡

ã€å»ºè®®ã€‘è¯·è°¨æ…æŠ•èµ„ï¼""",
            "description": "åŒ…å«å¤æ‚æ ¼å¼ã€è¡¨æƒ…ç¬¦å·ã€ç‰¹æ®Šç¬¦å·çš„å†…å®¹"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        print(f"\n--- æ¡ˆä¾‹ {i}: {case['name']} ---")
        print(f"ğŸ“ {case['description']}")
        
        original = case['original']
        cleaned = text_cleaner.clean_for_tts(original)
        
        print(f"ğŸ“ åŸå§‹: {original}")
        print(f"ğŸ¤ ä¼˜åŒ–: {cleaned}")
        
        reduction = len(original) - len(cleaned)
        reduction_rate = (reduction / len(original)) * 100 if len(original) > 0 else 0
        
        print(f"ğŸ“Š å‡å°‘ {reduction} å­—ç¬¦ ({reduction_rate:.1f}%)")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤ TTSæ–‡æœ¬ä¼˜åŒ–æ¼”ç¤º")
    print("=" * 60)
    
    try:
        # ä¸»è¦æ¼”ç¤º
        demo_text_optimization()
        
        # å¯¹æ¯”æ¼”ç¤º
        demo_comparison()
        
        print("\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
        print("\nğŸ’¡ æ€»ç»“:")
        print("âœ… æ–‡æœ¬æ¸…ç†åŠŸèƒ½èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤§æ¨¡å‹è¾“å‡º")
        print("âœ… ç§»é™¤è¡¨æƒ…ç¬¦å·ã€ç‰¹æ®Šç¬¦å·ã€æ ¼å¼æ ‡è®°")
        print("âœ… å°†åˆ—è¡¨æ ¼å¼è½¬æ¢ä¸ºè‡ªç„¶è¯­è¨€")
        print("âœ… ç”Ÿæˆé€‚åˆTTSè¯­éŸ³åˆæˆçš„æ–‡æœ¬")
        print("âœ… ä¿æŒè¯­ä¹‰å®Œæ•´æ€§çš„åŒæ—¶ä¼˜åŒ–æœ—è¯»æ•ˆæœ")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 