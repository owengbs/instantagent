import { useState, useRef, useCallback, useEffect } from 'react'

interface RealtimeChatOptions {
  onMessage?: (message: any) => void
  onError?: (error: string) => void
  onConnect?: () => void
  onDisconnect?: () => void
}

interface RealtimeChatReturn {
  isConnected: boolean
  isConnecting: boolean
  error: string | null
  sendMessage: (message: string) => void
  setVoice: (voice: string) => void
  startASR: () => void
  stopASR: () => void
  sendAudioData: (audioData: ArrayBuffer) => void
  aiTextBuffer: string
  currentSentences: string[]
  isProcessing: boolean
  isSpeaking: boolean
}

const API_BASE_URL = 'ws://localhost:8000/api/realtime/ws'

// éŸ³é¢‘æ’­æ”¾å™¨ç±»
class RealtimeAudioPlayer {
  private context: AudioContext
  private sequenceQueue: Map<number, { chunks: Int16Array[], isComplete: boolean }> = new Map()
  private currentSequence: number = 0
  private isPlaying: boolean = false
  private sampleRate: number

  constructor(sampleRate: number = 24000) {
    this.context = new (window.AudioContext || (window as any).webkitAudioContext)()
    this.sampleRate = sampleRate
  }

  async addAudioChunk(sequence: number, _chunkIndex: number, audioData: string): Promise<void> {
    try {
      // è§£ç base64éŸ³é¢‘æ•°æ®
      const audioBytes = Uint8Array.from(atob(audioData), c => c.charCodeAt(0))
      const audioArray = new Int16Array(audioBytes.buffer)

      // è·å–æˆ–åˆ›å»ºåºåˆ—
      if (!this.sequenceQueue.has(sequence)) {
        this.sequenceQueue.set(sequence, { chunks: [], isComplete: false })
      }

      const sequenceData = this.sequenceQueue.get(sequence)!
      sequenceData.chunks.push(audioArray)

      // å¦‚æœå½“å‰åºåˆ—æ­£åœ¨æ’­æ”¾ï¼Œç«‹å³æ’­æ”¾æ–°ç‰‡æ®µ
      if (sequence === this.currentSequence && this.isPlaying) {
        await this.playAudioChunk(audioArray)
      }
    } catch (error) {
      console.error('âŒ æ·»åŠ éŸ³é¢‘ç‰‡æ®µå¤±è´¥:', error)
    }
  }

  markSequenceComplete(sequence: number): void {
    const sequenceData = this.sequenceQueue.get(sequence)
    if (sequenceData) {
      sequenceData.isComplete = true
    }
  }

  async playNextSequence(): Promise<void> {
    if (this.isPlaying) return

    // æŸ¥æ‰¾ä¸‹ä¸€ä¸ªå®Œæ•´çš„åºåˆ—
    for (const [sequence, data] of this.sequenceQueue) {
      if (sequence >= this.currentSequence && data.isComplete) {
        this.currentSequence = sequence
        this.isPlaying = true

        try {
          // æ’­æ”¾åºåˆ—ä¸­çš„æ‰€æœ‰ç‰‡æ®µ
          for (const chunk of data.chunks) {
            await this.playAudioChunk(chunk)
          }

          // æ¸…ç†å·²æ’­æ”¾çš„åºåˆ—
          this.sequenceQueue.delete(sequence)
          this.currentSequence++
        } finally {
          this.isPlaying = false
        }

        // ç»§ç»­æ’­æ”¾ä¸‹ä¸€ä¸ªåºåˆ—
        await this.playNextSequence()
        break
      }
    }
  }

  private async playAudioChunk(audioArray: Int16Array): Promise<void> {
    return new Promise((resolve) => {
      // åˆ›å»ºéŸ³é¢‘ç¼“å†²åŒº
      const audioBuffer = this.context.createBuffer(1, audioArray.length, this.sampleRate)
      const channelData = audioBuffer.getChannelData(0)

      // å°†Int16Arrayè½¬æ¢ä¸ºFloat32Array
      for (let i = 0; i < audioArray.length; i++) {
        channelData[i] = audioArray[i] / 32768.0
      }

      // åˆ›å»ºéŸ³é¢‘æºå¹¶æ’­æ”¾
      const source = this.context.createBufferSource()
      source.buffer = audioBuffer
      source.connect(this.context.destination)
      source.onended = () => resolve()
      source.start()
    })
  }

  getIsPlaying(): boolean {
    return this.isPlaying
  }

  stop(): void {
    this.isPlaying = false
    this.sequenceQueue.clear()
    this.currentSequence = 0
  }
}

export const useRealtimeChat = (options: RealtimeChatOptions = {}): RealtimeChatReturn => {
  const {
    onMessage,
    onError,
    onConnect,
    onDisconnect
  } = options

  const [isConnected, setIsConnected] = useState(false)
  const [isConnecting, setIsConnecting] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [aiTextBuffer, setAiTextBuffer] = useState('')
  const [currentSentences] = useState<string[]>([])
  const [isProcessing, setIsProcessing] = useState(false)
  const [isSpeaking, setIsSpeaking] = useState(false)

  const wsRef = useRef<WebSocket | null>(null)
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const audioPlayerRef = useRef<RealtimeAudioPlayer | null>(null)
  const clientIdRef = useRef<string>('')

  // ç”Ÿæˆå®¢æˆ·ç«¯ID
  useEffect(() => {
    clientIdRef.current = `client_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }, [])

  // å¤„ç†WebSocketæ¶ˆæ¯
  const handleWebSocketMessage = useCallback((event: MessageEvent) => {
    try {
      const data = JSON.parse(event.data)
      const { type } = data

      switch (type) {
        case 'welcome':
          console.log('âœ… å®æ—¶å¯¹è¯æœåŠ¡å·²è¿æ¥')
          onMessage?.(data)
          break

        case 'ai_text_chunk':
          // AIæ–‡æœ¬ç‰‡æ®µ
          setAiTextBuffer(prev => prev + data.content)
          onMessage?.(data)
          break

        case 'tts_start':
          // TTSå¼€å§‹
          setIsSpeaking(true)
          onMessage?.(data)
          break

        case 'audio_chunk':
          // éŸ³é¢‘ç‰‡æ®µ
          if (audioPlayerRef.current) {
            audioPlayerRef.current.addAudioChunk(
              data.sequence,
              data.chunk_index,
              data.audio_data
            )
          }
          onMessage?.(data)
          break

        case 'tts_complete':
          // TTSå®Œæˆ
          if (audioPlayerRef.current) {
            audioPlayerRef.current.markSequenceComplete(data.sequence)
            audioPlayerRef.current.playNextSequence()
          }
          setIsSpeaking(false)
          onMessage?.(data)
          break

        case 'processing_start':
          // å¤„ç†å¼€å§‹
          setIsProcessing(true)
          setAiTextBuffer('')
          onMessage?.(data)
          break

        case 'processing_complete':
          // å¤„ç†å®Œæˆ
          setIsProcessing(false)
          onMessage?.(data)
          break

        case 'asr_partial':
          // ASRéƒ¨åˆ†ç»“æœ
          onMessage?.(data)
          break

        case 'asr_start':
        case 'asr_stop':
        case 'voice_set':
        case 'asr_model_set':
        case 'audio_received':
          // å…¶ä»–äº‹ä»¶
          onMessage?.(data)
          break

        case 'error':
          console.error('âŒ æœåŠ¡å™¨é”™è¯¯:', data.message)
          setError(data.message)
          onError?.(data.message)
          break

        case 'pong':
          // å¿ƒè·³å“åº”
          break

        default:
          console.log('ğŸ“¨ æœªçŸ¥æ¶ˆæ¯ç±»å‹:', type, data)
      }
    } catch (err) {
      console.error('âŒ å¤„ç†WebSocketæ¶ˆæ¯å¤±è´¥:', err)
    }
  }, [onMessage, onError])

  // è¿æ¥WebSocket
  const connectWebSocket = useCallback(async () => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      return
    }

    console.log('ğŸ”Œ è¿æ¥å®æ—¶å¯¹è¯WebSocket...')
    setError(null)
    setIsConnecting(true)

    try {
      const ws = new WebSocket(`${API_BASE_URL}/${clientIdRef.current}`)
      wsRef.current = ws

      ws.onopen = () => {
        console.log('âœ… å®æ—¶å¯¹è¯WebSocketè¿æ¥æˆåŠŸ')
        setIsConnecting(false)
        setIsConnected(true)
        setError(null)
        onConnect?.()
      }

      ws.onmessage = handleWebSocketMessage

      ws.onclose = (event) => {
        console.log('ğŸ”Œ å®æ—¶å¯¹è¯WebSocketè¿æ¥å…³é—­:', event.code, event.reason)
        setIsConnecting(false)
        setIsConnected(false)
        onDisconnect?.()
        
        // è‡ªåŠ¨é‡è¿ï¼ˆé™¤éæ˜¯æ­£å¸¸å…³é—­ï¼‰
        if (event.code !== 1000) {
          scheduleReconnect()
        }
      }

      ws.onerror = (error) => {
        console.error('âŒ å®æ—¶å¯¹è¯WebSocketé”™è¯¯:', error)
        setError('WebSocketè¿æ¥é”™è¯¯')
        setIsConnecting(false)
        setIsConnected(false)
      }

    } catch (err) {
      console.error('âŒ åˆ›å»ºå®æ—¶å¯¹è¯WebSocketè¿æ¥å¤±è´¥:', err)
      setError('æ— æ³•å»ºç«‹è¿æ¥')
      setIsConnecting(false)
    }
  }, [handleWebSocketMessage, onConnect, onDisconnect])

  // é‡è¿è°ƒåº¦
  const scheduleReconnect = useCallback(() => {
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current)
    }
    
    reconnectTimeoutRef.current = setTimeout(() => {
      console.log('ğŸ”„ å°è¯•é‡è¿å®æ—¶å¯¹è¯WebSocket...')
      connectWebSocket()
    }, 3000)
  }, [connectWebSocket])

  // å‘é€æ¶ˆæ¯
  const sendMessage = useCallback((message: string) => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'chat',
        message: message
      }))
    }
  }, [])

  // è®¾ç½®è¯­éŸ³
  const setVoice = useCallback((voice: string) => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'set_voice',
        voice: voice
      }))
    }
  }, [])

  // å¼€å§‹ASR
  const startASR = useCallback(() => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'asr_start'
      }))
    }
  }, [])

  // åœæ­¢ASR
  const stopASR = useCallback(() => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({
        type: 'asr_stop'
      }))
    }
  }, [])

  // å‘é€éŸ³é¢‘æ•°æ®
  const sendAudioData = useCallback((audioData: ArrayBuffer) => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(audioData)
    }
  }, [])

  // åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾å™¨
  useEffect(() => {
    audioPlayerRef.current = new RealtimeAudioPlayer()
    return () => {
      audioPlayerRef.current?.stop()
    }
  }, [])

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      if (reconnectTimeoutRef.current) {
        clearTimeout(reconnectTimeoutRef.current)
      }
      
      if (wsRef.current) {
        wsRef.current.close()
      }
      
      audioPlayerRef.current?.stop()
    }
  }, [])

  return {
    isConnected,
    isConnecting,
    error,
    sendMessage,
    setVoice,
    startASR,
    stopASR,
    sendAudioData,
    aiTextBuffer,
    currentSentences,
    isProcessing,
    isSpeaking
  }
} 