import { useState, useEffect, useRef, useCallback } from 'react'

interface SpeechRecognitionResult {
  transcript: string
  isFinal: boolean
  confidence: number
}

interface UseSpeechRecognitionOptions {
  language?: string
  continuous?: boolean
  interimResults?: boolean
  onResult?: (result: SpeechRecognitionResult) => void
  onError?: (error: string) => void
  onStart?: () => void
  onEnd?: () => void
}

interface UseSpeechRecognitionReturn {
  isSupported: boolean
  isListening: boolean
  transcript: string
  interimTranscript: string
  finalTranscript: string
  confidence: number
  error: string | null
  startListening: () => void
  stopListening: () => void
  resetTranscript: () => void
}

// ç±»åž‹å£°æ˜Žå¢žå¼º
declare global {
  interface Window {
    SpeechRecognition: any
    webkitSpeechRecognition: any
  }
}

export const useSpeechRecognition = (
  options: UseSpeechRecognitionOptions = {}
): UseSpeechRecognitionReturn => {
  const {
    language = 'zh-CN',
    continuous = true,
    interimResults = true,
    onResult,
    onError,
    onStart,
    onEnd
  } = options

  const [isSupported] = useState(() => {
    return !!(window.SpeechRecognition || window.webkitSpeechRecognition)
  })

  const [isListening, setIsListening] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [interimTranscript, setInterimTranscript] = useState('')
  const [finalTranscript, setFinalTranscript] = useState('')
  const [confidence, setConfidence] = useState(0)
  const [error, setError] = useState<string | null>(null)

  const recognitionRef = useRef<any>(null)
  const timeoutRef = useRef<NodeJS.Timeout | null>(null)

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  useEffect(() => {
    if (!isSupported) return

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    recognitionRef.current = new SpeechRecognition()

    const recognition = recognitionRef.current
    recognition.language = language
    recognition.continuous = continuous
    recognition.interimResults = interimResults
    recognition.maxAlternatives = 1

    recognition.onstart = () => {
      setIsListening(true)
      setError(null)
      onStart?.()
    }

    recognition.onresult = (event: any) => {
      let interim = ''
      let final = ''

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i]
        const transcriptPart = result[0].transcript

        if (result.isFinal) {
          final += transcriptPart
          setConfidence(result[0].confidence || 0)
        } else {
          interim += transcriptPart
        }
      }

      setInterimTranscript(interim)
      if (final) {
        setFinalTranscript(prev => prev + final)
        setTranscript(prev => prev + final)
      }

      // è°ƒç”¨å›žè°ƒå‡½æ•°
      if (final || interim) {
        onResult?.({
          transcript: final || interim,
          isFinal: !!final,
          confidence: confidence
        })
      }

      // å¦‚æžœæœ‰æœ€ç»ˆç»“æžœä¸”ä¸æ˜¯è¿žç»­æ¨¡å¼ï¼Œè‡ªåŠ¨åœæ­¢
      if (final && !continuous) {
        stopListening()
      }
    }

    recognition.onerror = (event: any) => {
      console.error('ðŸš¨ è¯­éŸ³è¯†åˆ«é”™è¯¯äº‹ä»¶:', event)
      
      let errorMessage = 'è¯­éŸ³è¯†åˆ«å‡ºçŽ°é—®é¢˜'
      
      switch (event.error) {
        case 'not-allowed':
          errorMessage = 'éº¦å…‹é£Žæƒé™è¢«æ‹’ç»ï¼Œè¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸è®¿é—®éº¦å…‹é£Ž'
          break
        case 'no-speech':
          errorMessage = 'æ²¡æœ‰æ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·é‡è¯•'
          break
        case 'audio-capture':
          errorMessage = 'æ— æ³•æ•èŽ·éŸ³é¢‘ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£Žè¿žæŽ¥'
          break
        case 'network':
          errorMessage = 'ç½‘ç»œè¿žæŽ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥'
          break
        case 'service-not-allowed':
          errorMessage = 'è¯­éŸ³è¯†åˆ«æœåŠ¡ä¸å¯ç”¨'
          break
        case 'bad-grammar':
          errorMessage = 'è¯­éŸ³è¯†åˆ«é…ç½®é”™è¯¯'
          break
        case 'language-not-supported':
          errorMessage = 'ä¸æ”¯æŒå½“å‰è¯­è¨€'
          break
        default:
          errorMessage = `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`
      }
      
      console.error('âŒ è¯­éŸ³è¯†åˆ«é”™è¯¯:', errorMessage)
      setError(errorMessage)
      setIsListening(false)
      onError?.(errorMessage)
    }

    recognition.onend = () => {
      setIsListening(false)
      onEnd?.()
    }

    return () => {
      if (recognition) {
        recognition.abort()
      }
    }
  }, [language, continuous, interimResults, onResult, onError, onStart, onEnd, isSupported])

  // å¼€å§‹ç›‘å¬
  const startListening = useCallback(() => {
    console.log('ðŸŽ™ï¸ startListening è¢«è°ƒç”¨', {
      isSupported,
      hasRecognition: !!recognitionRef.current,
      isListening,
      error
    })

    if (!isSupported) {
      const errorMsg = 'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½'
      setError(errorMsg)
      console.error('âŒ', errorMsg)
      return
    }

    if (!recognitionRef.current) {
      const errorMsg = 'è¯­éŸ³è¯†åˆ«å¯¹è±¡æœªåˆå§‹åŒ–'
      setError(errorMsg)
      console.error('âŒ', errorMsg)
      return
    }

    if (isListening) {
      console.log('âš ï¸ å·²ç»åœ¨ç›‘å¬ä¸­ï¼Œå¿½ç•¥é‡å¤è°ƒç”¨')
      return
    }

    try {
      console.log('ðŸš€ å‡†å¤‡å¯åŠ¨è¯­éŸ³è¯†åˆ«...')
      setError(null)
      setInterimTranscript('')
      
      // ç¡®ä¿ä¹‹å‰çš„è¯†åˆ«å·²åœæ­¢
      try {
        recognitionRef.current.stop()
      } catch (e) {
        // å¿½ç•¥åœæ­¢é”™è¯¯
      }
      
      // çŸ­æš‚å»¶è¿ŸåŽå¯åŠ¨
      setTimeout(() => {
        try {
          console.log('ðŸŽ¯ æ­£åœ¨å¯åŠ¨è¯­éŸ³è¯†åˆ«...')
          recognitionRef.current!.start()
        } catch (startErr: any) {
          console.error('âŒ å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', startErr)
          
          let errorMessage = 'å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥'
          if (startErr.name === 'NotAllowedError') {
            errorMessage = 'éº¦å…‹é£Žæƒé™è¢«æ‹’ç»ï¼Œè¯·å…è®¸è®¿é—®éº¦å…‹é£Ž'
          } else if (startErr.name === 'NotFoundError') {
            errorMessage = 'æœªæ‰¾åˆ°éº¦å…‹é£Žè®¾å¤‡'
          } else if (startErr.name === 'NotSupportedError') {
            errorMessage = 'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«'
          } else if (startErr.message?.includes('already started')) {
            errorMessage = 'è¯­éŸ³è¯†åˆ«å·²åœ¨è¿è¡Œä¸­'
          }
          
          setError(errorMessage)
        }
      }, 100)

      // æ·»åŠ è¶…æ—¶ä¿æŠ¤
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current)
      }
      timeoutRef.current = setTimeout(() => {
        console.log('â° è¯­éŸ³è¯†åˆ«è¶…æ—¶ï¼Œè‡ªåŠ¨åœæ­¢')
        if (isListening) {
          stopListening()
        }
      }, 30000) // 30ç§’è¶…æ—¶
      
    } catch (err: any) {
      const errorMessage = `å¯åŠ¨è¯­éŸ³è¯†åˆ«å¼‚å¸¸: ${err.message || err}`
      setError(errorMessage)
      console.error('âŒ è¯­éŸ³è¯†åˆ«å¯åŠ¨å¼‚å¸¸:', err)
    }
  }, [isSupported, isListening, error])

  // åœæ­¢ç›‘å¬
  const stopListening = useCallback(() => {
    if (!recognitionRef.current || !isListening) return

    try {
      recognitionRef.current.stop()
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current)
        timeoutRef.current = null
      }
    } catch (err) {
      console.error('Speech recognition stop error:', err)
    }
  }, [isListening])

  // é‡ç½®è½¬å½•
  const resetTranscript = useCallback(() => {
    setTranscript('')
    setInterimTranscript('')
    setFinalTranscript('')
    setConfidence(0)
  }, [])

  // æ¸…ç†
  useEffect(() => {
    return () => {
      if (timeoutRef.current) {
        clearTimeout(timeoutRef.current)
      }
      if (recognitionRef.current && isListening) {
        recognitionRef.current.abort()
      }
    }
  }, [isListening])

  return {
    isSupported,
    isListening,
    transcript,
    interimTranscript,
    finalTranscript,
    confidence,
    error,
    startListening,
    stopListening,
    resetTranscript
  }
} 