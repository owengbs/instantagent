import React, { useState, useCallback, useRef, useEffect } from 'react'
import { useChat } from '../contexts/ChatContext'
import { useQwenTTS } from './useQwenTTS'

interface QwenSpeechRecognitionOptions {
  language?: string
  model?: string
  onStart?: () => void
  onEnd?: () => void
  onResult?: (text: string, isFinal: boolean) => void
  onError?: (error: string) => void
}

interface QwenSpeechRecognitionReturn {
  isSupported: boolean
  isListening: boolean
  isConnecting: boolean
  transcript: string
  finalTranscript: string
  error: string | null
  startListening: () => Promise<void>
  stopListening: () => void
  resetTranscript: () => void
  testSilenceDetection: () => void // æ·»åŠ æµ‹è¯•å‡½æ•°
}

const API_BASE_URL = process.env.NODE_ENV === 'development' 
  ? 'ws://localhost:8000/api/asr/ws'
  : `${window.location.protocol === 'https:' ? 'wss:' : 'ws:'}//${window.location.host}/api/asr/ws`

// Web Audio API éŸ³é¢‘é‡‡é›†å™¨
class AudioRecorder {
  private context: AudioContext
  private stream: MediaStream | null = null
  private processor: ScriptProcessorNode | null = null
  private isRecording = false
  private sampleRate: number
  private onAudioData: (data: Int16Array) => void
  
  // éŸ³é¢‘ç¼“å†²åŒº
  private pcmBuffer: Int16Array[] = []
  private bufferLength = 0
  private readonly chunkSize = 3200 // 200ms @ 16kHz, 16bit, å•å£°é“
  
  // é‡‡æ ·ç‡è­¦å‘Šæ ‡å¿—
  private sampleRateWarningShown = false

  // éŸ³é¢‘é‡é‡‡æ ·å‡½æ•°
  private resampleAudio(inputData: Float32Array, fromRate: number, toRate: number): Float32Array {
    if (fromRate === toRate) {
      return inputData
    }
    
    const ratio = toRate / fromRate
    const newLength = Math.round(inputData.length * ratio)
    const resampled = new Float32Array(newLength)
    
    for (let i = 0; i < newLength; i++) {
      const srcIndex = i / ratio
      const srcIndexFloor = Math.floor(srcIndex)
      const srcIndexCeil = Math.min(srcIndexFloor + 1, inputData.length - 1)
      const fraction = srcIndex - srcIndexFloor
      
      // çº¿æ€§æ’å€¼
      resampled[i] = inputData[srcIndexFloor] * (1 - fraction) + inputData[srcIndexCeil] * fraction
    }
    
    return resampled
  }

  constructor(sampleRate: number = 16000, onAudioData: (data: Int16Array) => void) {
    this.context = new (window.AudioContext || (window as any).webkitAudioContext)()
    this.sampleRate = sampleRate
    this.onAudioData = onAudioData
  }

  async start(): Promise<void> {
    try {
      // è·å–éº¦å…‹é£æƒé™ï¼Œç¡®ä¿æ­£ç¡®çš„éŸ³é¢‘å‚æ•°
      this.stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: this.sampleRate,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      })

      // åˆ›å»ºéŸ³é¢‘æº
      const source = this.context.createMediaStreamSource(this.stream)
      
      // åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨ - ä½¿ç”¨ScriptProcessorNodeç›´æ¥è·å–PCMæ•°æ®
      const bufferSize = 4096
      this.processor = this.context.createScriptProcessor(bufferSize, 1, 1)
      
      // å¤„ç†éŸ³é¢‘æ•°æ®
      this.processor.onaudioprocess = (event) => {
        if (!this.isRecording) return
        
        const inputBuffer = event.inputBuffer
        const inputData = inputBuffer.getChannelData(0)
        
        // æ£€æŸ¥é‡‡æ ·ç‡å¹¶é‡é‡‡æ ·
        let processedData = inputData
        if (inputBuffer.sampleRate !== this.sampleRate) {
          if (!this.sampleRateWarningShown) {
            console.warn(`âš ï¸ é‡‡æ ·ç‡ä¸åŒ¹é…: æœŸæœ›${this.sampleRate}Hz, å®é™…${inputBuffer.sampleRate}Hzï¼Œè¿›è¡Œé‡é‡‡æ ·`)
            this.sampleRateWarningShown = true
          }
          processedData = this.resampleAudio(inputData, inputBuffer.sampleRate, this.sampleRate)
        }
        
        // è½¬æ¢ä¸ºInt16Array (PCMæ ¼å¼)
        const pcmData = new Int16Array(processedData.length)
        for (let i = 0; i < processedData.length; i++) {
          // ç¡®ä¿éŸ³é¢‘æ•°æ®åœ¨æœ‰æ•ˆèŒƒå›´å†…
          const sample = Math.max(-1, Math.min(1, processedData[i]))
          pcmData[i] = Math.max(-32768, Math.min(32767, sample * 32768))
        }
        
        // æ·»åŠ åˆ°ç¼“å†²åŒº
        this.pcmBuffer.push(pcmData)
        this.bufferLength += pcmData.length
        
        // åˆå¹¶åˆ°200msä¸€å—å†å‘é€
        while (this.bufferLength >= this.chunkSize) {
          let merged = new Int16Array(this.chunkSize)
          let offset = 0
          
          while (offset < this.chunkSize && this.pcmBuffer.length > 0) {
            let chunk = this.pcmBuffer[0]
            let copyLen = Math.min(chunk.length, this.chunkSize - offset)
            merged.set(chunk.subarray(0, copyLen), offset)
            offset += copyLen
            
            if (copyLen < chunk.length) {
              // è¿˜æœ‰å‰©ä½™æ•°æ®ï¼Œæ›´æ–°ç¬¬ä¸€ä¸ªå—
              this.pcmBuffer[0] = chunk.subarray(copyLen)
            } else {
              // è¿™ä¸ªå—ç”¨å®Œäº†ï¼Œç§»é™¤
              this.pcmBuffer.shift()
            }
          }
          
          this.bufferLength -= this.chunkSize
          
          // å‘é€åˆå¹¶åçš„éŸ³é¢‘å—
          this.onAudioData(merged)
        }
      }
      
      // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
      source.connect(this.processor)
      this.processor.connect(this.context.destination)
      
      this.isRecording = true
      
    } catch (error) {
      throw new Error(`å¯åŠ¨éŸ³é¢‘å½•åˆ¶å¤±è´¥: ${error}`)
    }
  }

  stop(): void {
    this.isRecording = false
    
    // æ¸…ç©ºç¼“å†²åŒº
    this.pcmBuffer = []
    this.bufferLength = 0
    
    if (this.processor) {
      this.processor.disconnect()
      this.processor = null
    }
    
    if (this.stream) {
      this.stream.getTracks().forEach(track => track.stop())
      this.stream = null
    }
  }

  getIsRecording(): boolean {
    return this.isRecording
  }
}

export const useQwenSpeechRecognition = (options: QwenSpeechRecognitionOptions = {}): QwenSpeechRecognitionReturn => {
  const {
    language = 'zh-CN',
    model = 'paraformer-realtime-v2',
    onStart,
    onEnd,
    onResult,
    onError
  } = options

  const [isSupported] = useState(true) // å‡è®¾æµè§ˆå™¨æ”¯æŒWeb Audio API
  const [isListening, setIsListening] = useState(false)
  const [isConnecting, setIsConnecting] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [finalTranscript, setFinalTranscript] = useState('')
  const [error, setError] = useState<string | null>(null)

  const recorderRef = useRef<AudioRecorder | null>(null)
  const wsRef = useRef<WebSocket | null>(null)
  const reconnectTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const clientIdRef = useRef<string>('')
  const autoStopTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const lastActivityTimeRef = useRef<number>(0)
  const silenceTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const lastSpeechTimeRef = useRef<number>(0)

  // è·å–èŠå¤©ä¸Šä¸‹æ–‡
  const { sendMessage } = useChat()
  
  // è·å–TTSåŠŸèƒ½
  const { speak, isSpeaking } = useQwenTTS({
    voice: 'Cherry',
    onStart: () => console.log('ğŸ”Š TTSå¼€å§‹æ’­æ”¾'),
    onEnd: () => {
      console.log('ğŸ”Š TTSæ’­æ”¾ç»“æŸï¼Œå‡†å¤‡ä¸‹ä¸€è½®å¯¹è¯')
      // TTSæ’­æ”¾ç»“æŸåï¼Œå¯ä»¥é‡æ–°å¼€å§‹å½•éŸ³
      // è¿™é‡Œå¯ä»¥æ·»åŠ é‡æ–°å¼€å§‹å½•éŸ³çš„é€»è¾‘
    },
    onError: (error) => {
      console.error('âŒ TTSæ’­æ”¾é”™è¯¯:', error)
      setError(`TTSæ’­æ”¾é”™è¯¯: ${error}`)
    }
  })

  // è®¾ç½®AIå›å¤çš„TTSæ’­æ”¾å›è°ƒ
  const { setOnNewAIResponse } = useChat()
  
  useEffect(() => {
    // è®¾ç½®AIå›å¤å›è°ƒï¼Œè‡ªåŠ¨æ’­æ”¾è¯­éŸ³
    setOnNewAIResponse((response: string) => {
      console.log('ğŸ¤– æ”¶åˆ°AIå›å¤ï¼Œå¼€å§‹TTSæ’­æ”¾:', response.slice(0, 50) + '...')
      speak(response).catch((error) => {
        console.error('âŒ TTSæ’­æ”¾å¤±è´¥:', error)
      })
    })
  }, [setOnNewAIResponse, speak])

  // åˆå§‹åŒ–å®¢æˆ·ç«¯ID
  useEffect(() => {
    clientIdRef.current = `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }, [])

  // è¯´è¯ç»“æŸæ£€æµ‹ï¼ˆ3ç§’é™éŸ³ï¼‰
  const resetSilenceTimer = useCallback(() => {
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current)
      console.log('ğŸ”„ é‡ç½®é™éŸ³è®¡æ—¶å™¨')
    }
    lastSpeechTimeRef.current = Date.now()
    
    // 3ç§’æ— è¯­éŸ³æ´»åŠ¨è‡ªåŠ¨åœæ­¢å¹¶å‘é€ç»™å¤§æ¨¡å‹
    silenceTimeoutRef.current = setTimeout(() => {
      console.log('â° 3ç§’é™éŸ³è®¡æ—¶å™¨åˆ°æœŸï¼å‡†å¤‡æ£€æŸ¥æ˜¯å¦å‘é€ç»™å¤§æ¨¡å‹...')
      console.log('ğŸ” å½“å‰çŠ¶æ€æ£€æŸ¥:', {
        isListening,
        transcript,
        finalTranscript,
        wsConnected: wsRef.current?.readyState === WebSocket.OPEN
      })
      
      // è·å–å½“å‰è¯†åˆ«ç»“æœï¼ˆæ— è®ºå½•éŸ³çŠ¶æ€å¦‚ä½•ï¼‰
      const currentText = transcript || finalTranscript
      console.log('ğŸ“ å½“å‰è¯†åˆ«ç»“æœ:', { transcript, finalTranscript, currentText })
      
      if (currentText && currentText.trim()) {
        console.log('âœ… é™éŸ³æ£€æµ‹è§¦å‘ï¼Œå‘é€è¯†åˆ«ç»“æœç»™å¤§æ¨¡å‹:', currentText)
        console.log('ğŸ“Š è¯†åˆ«ç»“æœè¯¦æƒ…:', {
          transcriptLength: transcript.length,
          finalTranscriptLength: finalTranscript.length,
          currentTextLength: currentText.length,
          hasValidText: currentText.trim().length > 0
        })
        
        // å¦‚æœè¿˜åœ¨å½•éŸ³ï¼Œå…ˆåœæ­¢å½•éŸ³
        if (isListening) {
          console.log('ğŸ›‘ åœæ­¢Qwenè¯­éŸ³è¯†åˆ«')
          
          // æ¸…ç†è‡ªåŠ¨åœæ­¢è®¡æ—¶å™¨
          if (autoStopTimeoutRef.current) {
            clearTimeout(autoStopTimeoutRef.current)
            autoStopTimeoutRef.current = null
          }

          // æ¸…ç†è¯´è¯ç»“æŸæ£€æµ‹è®¡æ—¶å™¨
          if (silenceTimeoutRef.current) {
            clearTimeout(silenceTimeoutRef.current)
            silenceTimeoutRef.current = null
          }
          
          // åœæ­¢éŸ³é¢‘å½•åˆ¶
          if (recorderRef.current) {
            recorderRef.current.stop()
            recorderRef.current = null
          }

          // å‘é€ç»“æŸä¿¡å·
          if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
            wsRef.current.send(JSON.stringify({ type: 'end' }))
          }

          setIsListening(false)
          onEnd?.()
        }
        
        // å‘é€sendè¯·æ±‚åˆ°åç«¯ï¼Œè®©åç«¯å¤„ç†å‘é€ç»™å¤§æ¨¡å‹
        if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
          console.log('ğŸ“¤ å‘é€sendè¯·æ±‚åˆ°åç«¯')
          wsRef.current.send(JSON.stringify({ type: 'send' }))
        } else {
          console.error('âŒ WebSocketæœªè¿æ¥ï¼Œæ— æ³•å‘é€sendè¯·æ±‚')
        }
      } else {
        console.log('âš ï¸ é™éŸ³æ£€æµ‹è§¦å‘ï¼Œä½†æ²¡æœ‰è¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬')
        console.log('ğŸ“Š ç©ºç»“æœè¯¦æƒ…:', {
          transcriptLength: transcript.length,
          finalTranscriptLength: finalTranscript.length,
          currentTextLength: currentText.length,
          hasValidText: currentText.trim().length > 0
        })
        
        // å¦‚æœè¿˜åœ¨å½•éŸ³ï¼Œåœæ­¢å½•éŸ³
        if (isListening) {
          console.log('ğŸ›‘ åœæ­¢Qwenè¯­éŸ³è¯†åˆ«')
          
          // æ¸…ç†è®¡æ—¶å™¨
          if (autoStopTimeoutRef.current) {
            clearTimeout(autoStopTimeoutRef.current)
            autoStopTimeoutRef.current = null
          }
          if (silenceTimeoutRef.current) {
            clearTimeout(silenceTimeoutRef.current)
            silenceTimeoutRef.current = null
          }
          
          // åœæ­¢éŸ³é¢‘å½•åˆ¶
          if (recorderRef.current) {
            recorderRef.current.stop()
            recorderRef.current = null
          }

          // å‘é€ç»“æŸä¿¡å·
          if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
            wsRef.current.send(JSON.stringify({ type: 'end' }))
          }

          setIsListening(false)
          onEnd?.()
        }
      }
    }, 3000)
    console.log('â° å¯åŠ¨3ç§’é™éŸ³è®¡æ—¶å™¨')
  }, [isListening, transcript, finalTranscript, sendMessage, onEnd])

  // è‡ªåŠ¨åœæ­¢æœºåˆ¶ï¼ˆ5ç§’æ— æ´»åŠ¨ï¼‰
  const resetAutoStopTimer = useCallback(() => {
    if (autoStopTimeoutRef.current) {
      clearTimeout(autoStopTimeoutRef.current)
    }
    lastActivityTimeRef.current = Date.now()
    
    // 5ç§’æ— æ´»åŠ¨è‡ªåŠ¨åœæ­¢
    autoStopTimeoutRef.current = setTimeout(() => {
      if (isListening) {
        console.log('â° è‡ªåŠ¨åœæ­¢è¯­éŸ³è¯†åˆ«ï¼ˆæ— æ´»åŠ¨è¶…æ—¶ï¼‰')
        // stopListening() // ç§»é™¤æ­¤è¡Œï¼Œé¿å…å¾ªç¯ä¾èµ–
      }
    }, 5000)
  }, [isListening])

  // ç®€å•çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹
  const detectSpeechActivity = useCallback((pcmData: Int16Array): boolean => {
    // è®¡ç®—éŸ³é¢‘æ•°æ®çš„RMSï¼ˆå‡æ–¹æ ¹ï¼‰å€¼ä½œä¸ºéŸ³é‡æŒ‡æ ‡
    let sum = 0
    for (let i = 0; i < pcmData.length; i++) {
      sum += pcmData[i] * pcmData[i]
    }
    const rms = Math.sqrt(sum / pcmData.length)
    
    // è®¾ç½®éŸ³é‡é˜ˆå€¼ï¼ˆé™ä½é˜ˆå€¼ï¼Œæé«˜æ£€æµ‹çµæ•åº¦ï¼‰
    const threshold = 500 // é™ä½é˜ˆå€¼ä»1000åˆ°500
    const hasSpeech = rms > threshold
    
    // æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼ˆå‡å°‘é¢‘ç‡ï¼Œåªåœ¨æœ‰è¯­éŸ³æ—¶æ˜¾ç¤ºï¼‰
    if (hasSpeech) {
      console.log(`ğŸ¤ è¯­éŸ³æ´»åŠ¨æ£€æµ‹: RMS=${rms.toFixed(0)}, é˜ˆå€¼=${threshold}, æ£€æµ‹åˆ°è¯­éŸ³`)
    } else {
      // å¶å°”æ˜¾ç¤ºé™éŸ³çŠ¶æ€ï¼Œå¸®åŠ©è°ƒè¯•
      if (Math.random() < 0.1) { // 10%çš„æ¦‚ç‡æ˜¾ç¤ºé™éŸ³æ—¥å¿—
        console.log(`ğŸ”‡ è¯­éŸ³æ´»åŠ¨æ£€æµ‹: RMS=${rms.toFixed(0)}, é˜ˆå€¼=${threshold}, é™éŸ³ä¸­`)
      }
    }
    
    return hasSpeech
  }, [])

  // éŸ³é¢‘æ•°æ®å›è°ƒ
  const handleAudioData = useCallback((pcmData: Int16Array) => {
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      try {
        // ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯16ä½PCMæ ¼å¼
        if (pcmData.length > 0) {
          // æ£€æµ‹æ˜¯å¦æœ‰è¯­éŸ³æ´»åŠ¨ï¼ˆç®€å•çš„éŸ³é‡æ£€æµ‹ï¼‰
          const hasSpeech = detectSpeechActivity(pcmData)
          
          if (hasSpeech) {
            // æœ‰è¯­éŸ³æ´»åŠ¨ï¼Œé‡ç½®é™éŸ³è®¡æ—¶å™¨
            resetSilenceTimer()
            console.log('ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³æ´»åŠ¨')
          }
          
          // è½¬æ¢ä¸ºArrayBuffer
          const buffer = pcmData.buffer
          
          // å‘é€éŸ³é¢‘æ•°æ®åˆ°WebSocketï¼ˆå‡å°‘æ—¥å¿—é¢‘ç‡ï¼‰
          if (hasSpeech) {
            console.log(`ğŸ¤ å‘é€éŸ³é¢‘æ•°æ®: ${pcmData.length} é‡‡æ ·ç‚¹, ${buffer.byteLength} å­—èŠ‚`)
          }
          wsRef.current.send(buffer)
          
          // é‡ç½®è‡ªåŠ¨åœæ­¢è®¡æ—¶å™¨
          resetAutoStopTimer()
        }
      } catch (error) {
        console.error('âŒ å‘é€éŸ³é¢‘æ•°æ®å¤±è´¥:', error)
      }
    } else {
      console.warn('âš ï¸ WebSocketæœªè¿æ¥ï¼Œæ— æ³•å‘é€éŸ³é¢‘æ•°æ®')
    }
  }, [resetAutoStopTimer, resetSilenceTimer, detectSpeechActivity])

  // è¿æ¥WebSocket
  const connectWebSocket = useCallback(async () => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      return
    }

    console.log('ğŸ”Œ è¿æ¥Qwen ASR WebSocket...')
    setError(null)
    setIsConnecting(true)

    try {
      const ws = new WebSocket(`${API_BASE_URL}/${clientIdRef.current}`)
      wsRef.current = ws

      ws.onopen = () => {
        console.log('âœ… Qwen ASR WebSocketè¿æ¥æˆåŠŸ')
        setIsConnecting(false)
        setError(null)
        
        // å‘é€è¯†åˆ«å¼€å§‹äº‹ä»¶
        const startMessage = {
          type: 'start',
          model: model,
          language: language
        }
        console.log('ğŸš€ å‘é€ASRå¼€å§‹æ¶ˆæ¯:', startMessage)
        ws.send(JSON.stringify(startMessage))
      }

      ws.onmessage = (event) => {
        console.log('ğŸ“¨ æ”¶åˆ°ASRæ¶ˆæ¯:', event.data)
        try {
          const data = JSON.parse(event.data)
          const { type, text, is_final } = data

          console.log('ğŸ“¨ æ”¶åˆ°WebSocketæ¶ˆæ¯:', { type, text, is_final, data })

          switch (type) {
            case 'partial':
              // éƒ¨åˆ†è¯†åˆ«ç»“æœ
              if (text && text.trim()) {
                console.log('ğŸ“ ASRéƒ¨åˆ†ç»“æœ:', text)
                setTranscript(text)
                onResult?.(text, false)
                console.log('ğŸ”„ å·²æ›´æ–°transcriptçŠ¶æ€:', text)
                // æ³¨æ„ï¼šä¸è¦åœ¨è¿™é‡Œé‡ç½®é™éŸ³è®¡æ—¶å™¨ï¼Œå› ä¸ºASRç»“æœå¯èƒ½å»¶è¿Ÿ
                // é™éŸ³æ£€æµ‹åº”è¯¥åŸºäºå®é™…çš„è¯­éŸ³æ´»åŠ¨ï¼Œè€Œä¸æ˜¯ASRç»“æœ
              } else {
                console.log('âš ï¸ æ”¶åˆ°ç©ºçš„ASRéƒ¨åˆ†ç»“æœ')
              }
              break

            case 'final':
              // æœ€ç»ˆè¯†åˆ«ç»“æœ
              if (text && text.trim()) {
                console.log('ğŸ“ ASRæœ€ç»ˆç»“æœ:', text)
                setFinalTranscript(prev => {
                  const newFinal = prev + text
                  console.log('ğŸ”„ æ›´æ–°finalTranscript:', { prev, text, newFinal })
                  return newFinal
                })
                setTranscript('') // æ¸…ç©ºéƒ¨åˆ†ç»“æœ
                onResult?.(text, true)
                console.log('âœ… å·²å¤„ç†ASRæœ€ç»ˆç»“æœ')
                
                // æ³¨æ„ï¼šä¸è¦åœ¨è¿™é‡Œé‡ç½®é™éŸ³è®¡æ—¶å™¨ï¼Œè®©é™éŸ³æ£€æµ‹åŸºäºå®é™…çš„è¯­éŸ³æ´»åŠ¨
              } else {
                console.log('âš ï¸ æ”¶åˆ°ç©ºçš„ASRæœ€ç»ˆç»“æœ')
              }
              break

            case 'sentence':
              // å¥å­çº§åˆ«è¯†åˆ«ç»“æœï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
              if (text && text.trim()) {
                console.log('ğŸ“ ASRå¥å­ç»“æœ:', text, 'is_final:', is_final)
                setFinalTranscript(prev => {
                  const newFinal = prev + text
                  console.log('ğŸ”„ æ›´æ–°finalTranscript (sentence):', { prev, text, newFinal })
                  return newFinal
                })
                setTranscript('') // æ¸…ç©ºéƒ¨åˆ†ç»“æœ
                onResult?.(text, is_final || false)
                
                // å¦‚æœæ˜¯æœ€ç»ˆç»“æœï¼Œåœæ­¢å½•éŸ³å¹¶å‘é€ç»™å¤§æ¨¡å‹
                // æ³¨æ„ï¼šå¦‚æœé™éŸ³æ£€æµ‹å·²ç»è§¦å‘ï¼Œè¿™é‡Œå°±ä¸éœ€è¦é‡å¤å‘é€äº†
                if (is_final && isListening) {
                  console.log('âœ… æ”¶åˆ°ASRæœ€ç»ˆè¯†åˆ«ç»“æœï¼Œå‡†å¤‡å‘é€ç»™å¤§æ¨¡å‹:', text)
                  
                  // åœæ­¢å½•éŸ³
                  // stopListening() // ç§»é™¤æ­¤è¡Œï¼Œé¿å…å¾ªç¯ä¾èµ–
                  
                  // å‘é€ç»™å¤§æ¨¡å‹è¿›è¡Œå¯¹è¯
                  console.log('ğŸ¤– å‘é€è¯­éŸ³è¯†åˆ«ç»“æœç»™å¤§æ¨¡å‹:', text)
                  sendMessage(text).then(() => {
                    console.log('âœ… è¯­éŸ³è¯†åˆ«ç»“æœå·²å‘é€ç»™å¤§æ¨¡å‹')
                  }).catch((error) => {
                    console.error('âŒ å‘é€ç»™å¤§æ¨¡å‹å¤±è´¥:', error)
                    setError('å‘é€ç»™å¤§æ¨¡å‹å¤±è´¥')
                  })
                }
                // æ³¨æ„ï¼šä¸è¦åœ¨è¿™é‡Œé‡ç½®é™éŸ³è®¡æ—¶å™¨ï¼Œè®©é™éŸ³æ£€æµ‹åŸºäºå®é™…çš„è¯­éŸ³æ´»åŠ¨
              } else {
                console.log('âš ï¸ æ”¶åˆ°ç©ºçš„ASRå¥å­ç»“æœ')
              }
              break

            case 'error':
              const errorMsg = data.message || 'è¯­éŸ³è¯†åˆ«é”™è¯¯'
              console.error('âŒ ASRé”™è¯¯:', errorMsg)
              setError(errorMsg)
              onError?.(errorMsg)
              break

            case 'end':
              console.log('âœ… ASRè¯†åˆ«ç»“æŸ')
              break

            case 'welcome':
              console.log('ğŸ‘‹ ASRæœåŠ¡æ¬¢è¿æ¶ˆæ¯:', data.message)
              break

            case 'send_success':
              // åç«¯æˆåŠŸå¤„ç†å‘é€è¯·æ±‚ï¼Œè°ƒç”¨sendMessage
              const message = data.message
              console.log('âœ… åç«¯å‘é€æˆåŠŸï¼Œè°ƒç”¨sendMessage:', message)
              sendMessage(message).then(() => {
                console.log('âœ… è¯­éŸ³è¯†åˆ«ç»“æœå·²å‘é€ç»™å¤§æ¨¡å‹')
              }).catch((error) => {
                console.error('âŒ å‘é€ç»™å¤§æ¨¡å‹å¤±è´¥:', error)
                setError('å‘é€ç»™å¤§æ¨¡å‹å¤±è´¥')
              })
              break

            case 'send_error':
              // åç«¯å‘é€å¤±è´¥
              const sendErrorMsg = data.message || 'å‘é€å¤±è´¥'
              console.error('âŒ åç«¯å‘é€å¤±è´¥:', sendErrorMsg)
              setError(sendErrorMsg)
              onError?.(sendErrorMsg)
              break

            case 'llm_response':
              // å¤§æ¨¡å‹å›å¤
              const llmMessage = data.message
              console.log('ğŸ¤– æ”¶åˆ°å¤§æ¨¡å‹å›å¤:', llmMessage)
              // è¿™é‡Œå¯ä»¥è§¦å‘TTSæ’­æ”¾
              break

            case 'llm_error':
              // å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥
              const llmErrorMsg = data.message || 'å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥'
              console.error('âŒ å¤§æ¨¡å‹è°ƒç”¨å¤±è´¥:', llmErrorMsg)
              setError(llmErrorMsg)
              onError?.(llmErrorMsg)
              break

            default:
              console.log('ğŸ“¨ æœªçŸ¥ASRæ¶ˆæ¯ç±»å‹:', type, data)
          }
        } catch (err) {
          console.error('âŒ å¤„ç†ASRæ¶ˆæ¯å¤±è´¥:', err)
        }
      }

      ws.onclose = (event) => {
        console.log('ğŸ”Œ Qwen ASR WebSocketè¿æ¥å…³é—­:', event.code, event.reason)
        setIsConnecting(false)
        setIsListening(false)
        
        // è‡ªåŠ¨é‡è¿ï¼ˆé™¤éæ˜¯æ­£å¸¸å…³é—­ï¼‰
        if (event.code !== 1000) {
          scheduleReconnect()
        }
      }

      ws.onerror = (error) => {
        console.error('âŒ Qwen ASR WebSocketé”™è¯¯:', error)
        setError('WebSocketè¿æ¥é”™è¯¯')
        setIsConnecting(false)
      }

    } catch (err) {
      console.error('âŒ åˆ›å»ºASR WebSocketè¿æ¥å¤±è´¥:', err)
      setError('æ— æ³•å»ºç«‹è¿æ¥')
      setIsConnecting(false)
    }
  }, [language, model, onResult, onError, sendMessage, isListening])

  // é‡è¿è°ƒåº¦
  const scheduleReconnect = useCallback(() => {
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current)
    }
    
    reconnectTimeoutRef.current = setTimeout(() => {
      console.log('ğŸ”„ å°è¯•é‡è¿Qwen ASR WebSocket...')
      connectWebSocket()
    }, 3000)
  }, [connectWebSocket])

  // å¼€å§‹ç›‘å¬
  const startListening = useCallback(async () => {
    try {
      console.log('ğŸ¤ å¼€å§‹Qwenè¯­éŸ³è¯†åˆ«...')
      setError(null)
      onStart?.()

      // è¿æ¥WebSocket
      await connectWebSocket()

      // åˆ›å»ºéŸ³é¢‘å½•åˆ¶å™¨
      recorderRef.current = new AudioRecorder(16000, handleAudioData)
      
      // å¼€å§‹å½•åˆ¶
      await recorderRef.current.start()
      setIsListening(true)
      
      // å¯åŠ¨è‡ªåŠ¨åœæ­¢è®¡æ—¶å™¨
      resetAutoStopTimer()
      
      console.log('âœ… Qwenè¯­éŸ³è¯†åˆ«å·²å¯åŠ¨')

    } catch (err) {
      console.error('âŒ å¯åŠ¨Qwenè¯­éŸ³è¯†åˆ«å¤±è´¥:', err)
      const errorMessage = err instanceof Error ? err.message : String(err)
      setError(errorMessage)
      onError?.(errorMessage)
    }
  }, [connectWebSocket, handleAudioData, onStart, onError, resetAutoStopTimer])

  // åœæ­¢ç›‘å¬
  const stopListening = useCallback(() => {
    console.log('ğŸ›‘ åœæ­¢Qwenè¯­éŸ³è¯†åˆ«')
    
    // æ¸…ç†è‡ªåŠ¨åœæ­¢è®¡æ—¶å™¨
    if (autoStopTimeoutRef.current) {
      clearTimeout(autoStopTimeoutRef.current)
      autoStopTimeoutRef.current = null
    }

    // æ¸…ç†è¯´è¯ç»“æŸæ£€æµ‹è®¡æ—¶å™¨
    if (silenceTimeoutRef.current) {
      clearTimeout(silenceTimeoutRef.current)
      silenceTimeoutRef.current = null
    }
    
    // åœæ­¢éŸ³é¢‘å½•åˆ¶
    if (recorderRef.current) {
      recorderRef.current.stop()
      recorderRef.current = null
    }

    // å‘é€ç»“æŸä¿¡å·
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(JSON.stringify({ type: 'end' }))
    }

    setIsListening(false)
    onEnd?.()
  }, [onEnd])

  // é‡ç½®è½¬å½•
  const resetTranscript = useCallback(() => {
    setTranscript('')
    setFinalTranscript('')
  }, [])

  // æ‰‹åŠ¨æµ‹è¯•é™éŸ³æ£€æµ‹ï¼ˆä»…ç”¨äºè°ƒè¯•ï¼‰
  const testSilenceDetection = useCallback(() => {
    console.log('ğŸ§ª æ‰‹åŠ¨æµ‹è¯•é™éŸ³æ£€æµ‹...')
    console.log('ğŸ“ å½“å‰è¯†åˆ«ç»“æœ:', { transcript, finalTranscript })
    
    // æ¨¡æ‹Ÿ3ç§’é™éŸ³æ£€æµ‹è§¦å‘
    const currentText = transcript || finalTranscript
    if (currentText && currentText.trim()) {
      console.log('âœ… æ‰‹åŠ¨è§¦å‘å‘é€ç»™å¤§æ¨¡å‹:', currentText)
      sendMessage(currentText).then(() => {
        console.log('âœ… æ‰‹åŠ¨æµ‹è¯•ï¼šè¯­éŸ³è¯†åˆ«ç»“æœå·²å‘é€ç»™å¤§æ¨¡å‹')
      }).catch((error) => {
        console.error('âŒ æ‰‹åŠ¨æµ‹è¯•ï¼šå‘é€ç»™å¤§æ¨¡å‹å¤±è´¥:', error)
      })
    } else {
      console.log('âš ï¸ æ‰‹åŠ¨æµ‹è¯•ï¼šæ²¡æœ‰è¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬')
    }
  }, [transcript, finalTranscript, sendMessage])

  // ç»„ä»¶å¸è½½æ—¶æ¸…ç†
  useEffect(() => {
    return () => {
      if (reconnectTimeoutRef.current) {
        clearTimeout(reconnectTimeoutRef.current)
      }
      
      if (autoStopTimeoutRef.current) {
        clearTimeout(autoStopTimeoutRef.current)
      }

      if (silenceTimeoutRef.current) {
        clearTimeout(silenceTimeoutRef.current)
      }
      
      if (wsRef.current) {
        wsRef.current.close()
      }
      
      if (recorderRef.current) {
        recorderRef.current.stop()
      }
    }
  }, [])

  return {
    isSupported,
    isListening,
    isConnecting,
    transcript,
    finalTranscript,
    error,
    startListening,
    stopListening,
    resetTranscript,
    testSilenceDetection // æ·»åŠ æµ‹è¯•å‡½æ•°
  }
} 