/**
 * æ™ºèƒ½è¯­éŸ³ç®¡ç†Hook - æ··åˆæ™ºèƒ½æ–¹æ¡ˆ
 * è§£å†³TTSæ’­æ”¾æ—¶è¯¯è¯†åˆ«ç”¨æˆ·è¯­éŸ³çš„é—®é¢˜
 */
import { useState, useCallback, useRef, useEffect } from 'react'

export interface VoiceActivityDetector {
  // éŸ³é¢‘èƒ½é‡æ£€æµ‹
  analyzeAudioEnergy: (audioData: Float32Array) => number
  // è¯­éŸ³æ´»åŠ¨æ£€æµ‹
  detectVoiceActivity: (audioData: Float32Array) => boolean
  // ç”¨æˆ·ä¸»åŠ¨å‘è¨€æ£€æµ‹
  detectUserSpeechIntent: (audioData: Float32Array, duration: number) => boolean
}

export interface SmartVoiceState {
  // éº¦å…‹é£çŠ¶æ€
  microphoneState: 'active' | 'reduced' | 'muted'
  // TTSæ’­æ”¾çŠ¶æ€
  isTTSPlaying: boolean
  // ç”¨æˆ·å‘è¨€æ£€æµ‹çŠ¶æ€
  isUserSpeaking: boolean
  // æ˜¯å¦å…è®¸æ‰“æ–­
  canInterrupt: boolean
  // éŸ³é¢‘èƒ½é‡çº§åˆ«
  audioEnergy: number
  // æ£€æµ‹åˆ°çš„è¯­éŸ³æ´»åŠ¨
  voiceActivity: boolean
}

export interface SmartVoiceManagerOptions {
  // è‡ªé€‚åº”é™éŸ³é…ç½®
  reducedSensitivity?: number // é™ä½çš„çµæ•åº¦æ¯”ä¾‹ (0-1)
  muteThreshold?: number // å®Œå…¨é™éŸ³çš„é˜ˆå€¼
  
  // æ‰“æ–­æ£€æµ‹é…ç½®
  interruptVolumeThreshold?: number // æ‰“æ–­éŸ³é‡é˜ˆå€¼
  interruptDurationThreshold?: number // æ‰“æ–­æŒç»­æ—¶é—´é˜ˆå€¼(ms)
  
  // VADé…ç½®
  voiceEnergyThreshold?: number // è¯­éŸ³èƒ½é‡é˜ˆå€¼
  voiceFrequencyRange?: [number, number] // è¯­éŸ³é¢‘ç‡èŒƒå›´
  
  // æ¢å¤é…ç½®
  recoveryDelay?: number // æ’­æ”¾ç»“æŸåæ¢å¤å»¶è¿Ÿ(ms)
  
  // å›è°ƒå‡½æ•°
  onStateChange?: (state: SmartVoiceState) => void
  onUserInterrupt?: () => void
  onTTSStart?: () => void
  onTTSEnd?: () => void
}

export interface SmartVoiceManagerReturn {
  // çŠ¶æ€
  state: SmartVoiceState
  
  // æ§åˆ¶æ–¹æ³•
  startTTSPlayback: () => void
  endTTSPlayback: () => void
  processAudioFrame: (audioData: Float32Array) => void
  
  // éº¦å…‹é£æ§åˆ¶
  setMicrophoneState: (state: SmartVoiceState['microphoneState']) => void
  
  // æ‰‹åŠ¨æ§åˆ¶
  enableUserInterrupt: () => void
  disableUserInterrupt: () => void
  
  // é‡ç½®æ–¹æ³•
  reset: () => void
}

class VoiceActivityDetectorImpl implements VoiceActivityDetector {
  private readonly options: Required<SmartVoiceManagerOptions>
  
  constructor(options: Required<SmartVoiceManagerOptions>) {
    this.options = options
  }
  
  analyzeAudioEnergy(audioData: Float32Array): number {
    let sum = 0
    for (let i = 0; i < audioData.length; i++) {
      sum += audioData[i] * audioData[i]
    }
    return Math.sqrt(sum / audioData.length)
  }
  
  detectVoiceActivity(audioData: Float32Array): boolean {
    const energy = this.analyzeAudioEnergy(audioData)
    return energy > this.options.voiceEnergyThreshold
  }
  
  detectUserSpeechIntent(audioData: Float32Array, duration: number): boolean {
    const energy = this.analyzeAudioEnergy(audioData)
    const hasEnoughEnergy = energy > this.options.interruptVolumeThreshold
    const hasEnoughDuration = duration > this.options.interruptDurationThreshold
    
    // é¢‘ç‡åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
    const hasVoiceFrequency = this.detectVoiceFrequency(audioData)
    
    return hasEnoughEnergy && hasEnoughDuration && hasVoiceFrequency
  }
  
  private detectVoiceFrequency(audioData: Float32Array): boolean {
    // ç®€åŒ–çš„é¢‘ç‡æ£€æµ‹ - å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨FFT
    // è¿™é‡Œç”¨ç®€å•çš„æ³¢å½¢ç‰¹å¾æ£€æµ‹
    let zeroCrossings = 0
    for (let i = 1; i < audioData.length; i++) {
      if ((audioData[i] >= 0) !== (audioData[i - 1] >= 0)) {
        zeroCrossings++
      }
    }
    
    // äººå£°é€šå¸¸åœ¨85-255 Hzä¹‹é—´ï¼Œå¯¹åº”çš„è¿‡é›¶ç‡
    const zeroCrossingRate = zeroCrossings / audioData.length
    return zeroCrossingRate > 0.02 && zeroCrossingRate < 0.3
  }
}

export const useSmartVoiceManager = (options: SmartVoiceManagerOptions = {}): SmartVoiceManagerReturn => {
  // é»˜è®¤é…ç½®
  const config: Required<SmartVoiceManagerOptions> = {
    reducedSensitivity: 0.2, // æ’­æ”¾æ—¶ä¿ç•™20%çµæ•åº¦
    muteThreshold: 0.05,
    interruptVolumeThreshold: 0.15, // è¾ƒé«˜çš„éŸ³é‡é˜ˆå€¼
    interruptDurationThreshold: 800, // 800msæŒç»­æ—¶é—´
    voiceEnergyThreshold: 0.03,
    voiceFrequencyRange: [85, 255],
    recoveryDelay: 500, // 500msæ¢å¤å»¶è¿Ÿ
    onStateChange: () => {},
    onUserInterrupt: () => {},
    onTTSStart: () => {},
    onTTSEnd: () => {},
    ...options
  }
  
  // åˆå§‹çŠ¶æ€
  const [state, setState] = useState<SmartVoiceState>({
    microphoneState: 'active',
    isTTSPlaying: false,
    isUserSpeaking: false,
    canInterrupt: true,
    audioEnergy: 0,
    voiceActivity: false
  })
  
  // Refs
  const vadRef = useRef<VoiceActivityDetector>(new VoiceActivityDetectorImpl(config))
  const speechStartTimeRef = useRef<number | null>(null)
  const recoveryTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const audioBufferRef = useRef<Float32Array[]>([])
  const frameCountRef = useRef<number>(0)
  
  // çŠ¶æ€æ›´æ–°å›è°ƒ
  useEffect(() => {
    config.onStateChange(state)
  }, [state, config])
  
  // æ›´æ–°çŠ¶æ€çš„è¾…åŠ©å‡½æ•°
  const updateState = useCallback((updates: Partial<SmartVoiceState>) => {
    setState(prev => ({ ...prev, ...updates }))
  }, [])
  
  // å¼€å§‹TTSæ’­æ”¾
  const startTTSPlayback = useCallback(() => {
    console.log('ğŸ”Š æ™ºèƒ½è¯­éŸ³ç®¡ç†: TTSæ’­æ”¾å¼€å§‹')
    
    // æ¸…é™¤æ¢å¤å®šæ—¶å™¨
    if (recoveryTimeoutRef.current) {
      clearTimeout(recoveryTimeoutRef.current)
      recoveryTimeoutRef.current = null
    }
    
    updateState({
      isTTSPlaying: true,
      microphoneState: 'reduced', // é™ä½çµæ•åº¦è€Œä¸æ˜¯å®Œå…¨é™éŸ³
      canInterrupt: true
    })
    
    config.onTTSStart()
  }, [updateState, config])
  
  // ç»“æŸTTSæ’­æ”¾
  const endTTSPlayback = useCallback(() => {
    console.log('ğŸ”Š æ™ºèƒ½è¯­éŸ³ç®¡ç†: TTSæ’­æ”¾ç»“æŸ')
    
    updateState({
      isTTSPlaying: false,
      isUserSpeaking: false
    })
    
    // å»¶è¿Ÿæ¢å¤éº¦å…‹é£çµæ•åº¦
    recoveryTimeoutRef.current = setTimeout(() => {
      console.log('ğŸ¤ æ™ºèƒ½è¯­éŸ³ç®¡ç†: æ¢å¤éº¦å…‹é£çµæ•åº¦')
      updateState({
        microphoneState: 'active',
        canInterrupt: true
      })
    }, config.recoveryDelay)
    
    config.onTTSEnd()
  }, [updateState, config])
  
  // å¤„ç†éŸ³é¢‘å¸§
  const processAudioFrame = useCallback((audioData: Float32Array) => {
    frameCountRef.current++
    
    // æ¯10å¸§åˆ†æä¸€æ¬¡ï¼ˆçº¦100msé—´éš”ï¼‰
    if (frameCountRef.current % 10 !== 0) {
      return
    }
    
    const vad = vadRef.current
    const energy = vad.analyzeAudioEnergy(audioData)
    const voiceActivity = vad.detectVoiceActivity(audioData)
    
    // æ›´æ–°éŸ³é¢‘èƒ½é‡å’Œè¯­éŸ³æ´»åŠ¨
    updateState({
      audioEnergy: energy,
      voiceActivity: voiceActivity
    })
    
    // TTSæ’­æ”¾æœŸé—´çš„ç‰¹æ®Šå¤„ç†
    if (state.isTTSPlaying && state.canInterrupt) {
      // æ£€æµ‹ç”¨æˆ·æ‰“æ–­æ„å›¾
      if (voiceActivity) {
        if (speechStartTimeRef.current === null) {
          speechStartTimeRef.current = Date.now()
        }
        
        const speechDuration = Date.now() - speechStartTimeRef.current
        const isUserIntent = vad.detectUserSpeechIntent(audioData, speechDuration)
        
        if (isUserIntent) {
          console.log('ğŸ—£ï¸ æ£€æµ‹åˆ°ç”¨æˆ·æ‰“æ–­æ„å›¾:', { energy, speechDuration })
          
          updateState({
            isUserSpeaking: true,
            microphoneState: 'active' // ç«‹å³æ¢å¤å®Œå…¨çµæ•åº¦
          })
          
          config.onUserInterrupt()
        }
      } else {
        // é‡ç½®è¯­éŸ³å¼€å§‹æ—¶é—´
        speechStartTimeRef.current = null
        updateState({
          isUserSpeaking: false
        })
      }
    } else if (!state.isTTSPlaying) {
      // éæ’­æ”¾æœŸé—´çš„æ­£å¸¸æ£€æµ‹
      updateState({
        isUserSpeaking: voiceActivity
      })
      
      if (voiceActivity) {
        speechStartTimeRef.current = Date.now()
      } else {
        speechStartTimeRef.current = null
      }
    }
  }, [state, updateState, config])
  
  // æ‰‹åŠ¨è®¾ç½®éº¦å…‹é£çŠ¶æ€
  const setMicrophoneState = useCallback((micState: SmartVoiceState['microphoneState']) => {
    updateState({ microphoneState: micState })
  }, [updateState])
  
  // å¯ç”¨ç”¨æˆ·æ‰“æ–­
  const enableUserInterrupt = useCallback(() => {
    updateState({ canInterrupt: true })
  }, [updateState])
  
  // ç¦ç”¨ç”¨æˆ·æ‰“æ–­
  const disableUserInterrupt = useCallback(() => {
    updateState({ canInterrupt: false })
  }, [updateState])
  
  // é‡ç½®çŠ¶æ€
  const reset = useCallback(() => {
    if (recoveryTimeoutRef.current) {
      clearTimeout(recoveryTimeoutRef.current)
      recoveryTimeoutRef.current = null
    }
    
    speechStartTimeRef.current = null
    frameCountRef.current = 0
    audioBufferRef.current = []
    
    setState({
      microphoneState: 'active',
      isTTSPlaying: false,
      isUserSpeaking: false,
      canInterrupt: true,
      audioEnergy: 0,
      voiceActivity: false
    })
  }, [])
  
  // æ¸…ç†
  useEffect(() => {
    return () => {
      if (recoveryTimeoutRef.current) {
        clearTimeout(recoveryTimeoutRef.current)
      }
    }
  }, [])
  
  return {
    state,
    startTTSPlayback,
    endTTSPlayback,
    processAudioFrame,
    setMicrophoneState,
    enableUserInterrupt,
    disableUserInterrupt,
    reset
  }
}

export default useSmartVoiceManager
