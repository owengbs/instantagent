import React, { useState, useRef, useEffect } from 'react'
import { motion, AnimatePresence } from 'framer-motion'
import { Mic, MicOff, Volume2, VolumeX, Send, Settings, Keyboard } from 'lucide-react'
import { useSpeechRecognition } from '../hooks/useSpeechRecognition'
import { useQwenTTS } from '../hooks/useQwenTTS'
import { useChat } from '../contexts/ChatContext'
import AudioVisualizer from './AudioVisualizer.tsx'
import { ChatInputProps } from '../types'

interface VoiceChatInputProps extends ChatInputProps {
  autoSpeak?: boolean
  showTextInput?: boolean
  onVoiceToggle?: (isVoiceMode: boolean) => void
}

const VoiceChatInput: React.FC<VoiceChatInputProps> = ({
  onSendMessage,
  disabled = false,
  placeholder = "ç‚¹å‡»éº¦å…‹é£è¯´è¯...",
  autoSpeak = true,
  showTextInput = true,
  onVoiceToggle
}) => {
  const [isVoiceMode, setIsVoiceMode] = useState(true)
  const [textInput, setTextInput] = useState('')
  const [lastAIResponse, setLastAIResponse] = useState('')
  const lastProcessedResponseRef = useRef('')
  const [showSettings, setShowSettings] = useState(false)
  const [speechSettings, setSpeechSettings] = useState({
    rate: 1,
    pitch: 1,
    volume: 1,
    voiceEnabled: true,
    selectedVoice: 'Cherry' // é»˜è®¤ä½¿ç”¨Cherryè¯­éŸ³
  })

  const textareaRef = useRef<HTMLTextAreaElement>(null)
  const { setOnNewAIResponse } = useChat()

  // è¯­éŸ³è¯†åˆ« - ä½¿ç”¨å’Œæµ‹è¯•é¡µé¢ç›¸åŒçš„ç®€åŒ–é…ç½®
  const {
    isSupported: recognitionSupported,
    isListening,
    finalTranscript,
    interimTranscript,
    error: recognitionError,
    startListening,
    stopListening,
    resetTranscript
  } = useSpeechRecognition({
    language: 'zh-CN',
    continuous: false,
    interimResults: true
  })

  // è¯­éŸ³ç»“æœå¤„ç†çŠ¶æ€
  const [lastProcessedTranscript, setLastProcessedTranscript] = useState('')

  // å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœ - ç›‘å¬finalTranscriptå˜åŒ–
  useEffect(() => {
    if (finalTranscript && finalTranscript.trim() && finalTranscript !== lastProcessedTranscript) {
      console.log('ğŸ¤ VoiceChatInput æ”¶åˆ°æœ€ç»ˆè¯­éŸ³ç»“æœ:', finalTranscript)
      setLastProcessedTranscript(finalTranscript)
      handleVoiceInput(finalTranscript.trim())
      
      // å»¶è¿Ÿé‡ç½®ï¼Œç¡®ä¿æ¶ˆæ¯å‘é€å®Œæˆ
      setTimeout(() => {
        resetTranscript()
        setLastProcessedTranscript('')
      }, 1000)
    }
  }, [finalTranscript, lastProcessedTranscript])

  // è°ƒè¯•æ—¥å¿—ï¼šç›‘æ§å…³é”®çŠ¶æ€å˜åŒ–ï¼ˆåªè®°å½•é‡è¦çŠ¶æ€ï¼‰
  useEffect(() => {
    if (isListening || recognitionError) {
      console.log('ğŸ” VoiceChatInput é‡è¦çŠ¶æ€å˜åŒ–:', {
        isListening,
        error: recognitionError,
        finalTranscript: finalTranscript?.slice(0, 20) + '...'
      })
    }
  }, [isListening, recognitionError, finalTranscript])

  // Qwen-TTS è¯­éŸ³åˆæˆ
  const {
    isSupported: synthesisSupported,
    isSpeaking,
    speak,
    stop: stopSpeaking,
    voices,
    error: synthesisError,
    isLoading: isSynthesisLoading
  } = useQwenTTS({
    voice: speechSettings.selectedVoice || 'Cherry',
    onStart: () => console.log('ğŸµ Qwen-TTS è¯­éŸ³åˆæˆå¼€å§‹'),
    onEnd: () => console.log('âœ… Qwen-TTS è¯­éŸ³åˆæˆç»“æŸ'),
    onError: (error) => console.error('âŒ Qwen-TTS é”™è¯¯:', error)
  })

  // å¤„ç†è¯­éŸ³è¾“å…¥
  const handleVoiceInput = async (transcript: string) => {
    console.log('ğŸ“¤ VoiceChatInput å‡†å¤‡å‘é€è¯­éŸ³æ¶ˆæ¯:', transcript)
    
    if (!transcript.trim() || disabled) {
      console.log('âš ï¸ è¯­éŸ³æ¶ˆæ¯è¢«å¿½ç•¥:', { transcript: transcript.trim(), disabled })
      return
    }

    try {
      console.log('ğŸš€ è°ƒç”¨ onSendMessage:', transcript)
      await onSendMessage(transcript)
      console.log('âœ… è¯­éŸ³æ¶ˆæ¯å‘é€æˆåŠŸ')
    } catch (error) {
      console.error('âŒ è¯­éŸ³æ¶ˆæ¯å‘é€å¤±è´¥:', error)
    }
    
    // é‡ç½®è½¬å½•
    resetTranscript()
  }

  // å¤„ç†æ–‡æœ¬è¾“å…¥
  const handleTextSubmit = () => {
    if (!textInput.trim() || disabled) return
    
    onSendMessage(textInput.trim())
    setTextInput('')
    
    // é‡ç½®textareaé«˜åº¦
    if (textareaRef.current) {
      textareaRef.current.style.height = 'auto'
    }
  }

  // è¯­éŸ³æ¨¡å¼åˆ‡æ¢
  const toggleVoiceMode = () => {
    const newMode = !isVoiceMode
    setIsVoiceMode(newMode)
    onVoiceToggle?.(newMode)
    
    if (!newMode && isListening) {
      stopListening()
    }
    
    if (newMode && isSpeaking) {
      stopSpeaking()
    }
  }

  // é¢„åˆå§‹åŒ–è¯­éŸ³åˆæˆï¼Œé¿å…æµè§ˆå™¨é™åˆ¶
  const preinitializeSpeech = () => {
    if (window.speechSynthesis && window.SpeechSynthesisUtterance) {
      try {
        console.log('ğŸ”§ é¢„åˆå§‹åŒ–è¯­éŸ³åˆæˆä»¥é¿å…æµè§ˆå™¨é™åˆ¶')
        // æ’­æ”¾ä¸€ä¸ªé™éŸ³çš„çŸ­è¯­éŸ³æ¥æ¿€æ´»è¯­éŸ³åˆæˆ
        const utterance = new SpeechSynthesisUtterance('')
        utterance.volume = 0
        utterance.rate = 10
        utterance.onend = () => {
          console.log('âœ… è¯­éŸ³åˆæˆé¢„åˆå§‹åŒ–å®Œæˆ')
        }
        window.speechSynthesis.speak(utterance)
      } catch (error) {
        console.log('âš ï¸ è¯­éŸ³åˆæˆé¢„åˆå§‹åŒ–å¤±è´¥:', error)
      }
    }
  }

  // éº¦å…‹é£æ§åˆ¶
  const handleMicClick = () => {
    console.log('ğŸ¤ VoiceChatInput éº¦å…‹é£æŒ‰é’®è¢«ç‚¹å‡»ï¼', {
      isListening,
      isSupported: recognitionSupported,
      disabled,
      isVoiceMode,
      error: recognitionError,
      timestamp: new Date().toISOString()
    })
    
    // åœ¨ç”¨æˆ·ç‚¹å‡»æ—¶é¢„åˆå§‹åŒ–è¯­éŸ³åˆæˆ
    preinitializeSpeech()
    
    if (isListening) {
      console.log('ğŸ›‘ VoiceChatInput åœæ­¢è¯­éŸ³è¯†åˆ«')
      stopListening()
    } else {
      console.log('ğŸ™ï¸ VoiceChatInput å‡†å¤‡å¼€å§‹è¯­éŸ³è¯†åˆ«')
      
      // æ£€æŸ¥æ”¯æŒæ€§å’Œæƒé™
      if (!recognitionSupported) {
        console.error('âŒ VoiceChatInput æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«')
        alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨Chromeã€Edgeæˆ–Safariæœ€æ–°ç‰ˆæœ¬')
        return
      }
      
      if (recognitionError) {
        console.error('âŒ VoiceChatInput è¯­éŸ³è¯†åˆ«é”™è¯¯:', recognitionError)
        alert(`è¯­éŸ³è¯†åˆ«é”™è¯¯: ${recognitionError}`)
        return
      }
      
      console.log('ğŸš€ VoiceChatInput å³å°†è°ƒç”¨ startListening()')
      console.log('ğŸ”§ å½“å‰è¯­éŸ³è¯†åˆ«çŠ¶æ€:', { isListening, recognitionSupported, disabled })
      
      // å…ˆé‡ç½®çŠ¶æ€ï¼Œç¡®ä¿æ²¡æœ‰æ®‹ç•™
      resetTranscript()
      
      // å»¶è¿Ÿè°ƒç”¨ï¼Œç¡®ä¿çŠ¶æ€æ›´æ–°
      setTimeout(() => {
        console.log('â° å»¶è¿Ÿè°ƒç”¨ startListening()')
        startListening()
        
        // å†æ¬¡æ£€æŸ¥çŠ¶æ€
        setTimeout(() => {
          console.log('ğŸ” startListeningè°ƒç”¨åçš„çŠ¶æ€æ£€æŸ¥:', { isListening })
        }, 500)
      }, 100)
    }
  }

  // (toggleSpeakingå‡½æ•°å·²è¢«handleManualPlayæ›¿ä»£)

  // é”®ç›˜äº‹ä»¶å¤„ç†
  const handleKeyDown = (e: React.KeyboardEvent<HTMLTextAreaElement>) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault()
      handleTextSubmit()
    }
  }

  // è‡ªåŠ¨è°ƒæ•´textareaé«˜åº¦
  const adjustTextareaHeight = () => {
    const textarea = textareaRef.current
    if (textarea) {
      textarea.style.height = 'auto'
      textarea.style.height = `${Math.min(textarea.scrollHeight, 120)}px`
    }
  }

  // å¤„ç†è¾“å…¥å˜åŒ–
  const handleInputChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {
    setTextInput(e.target.value)
    adjustTextareaHeight()
  }

  // ä½¿ç”¨ useRef å­˜å‚¨æœ€æ–°çš„speakå‡½æ•°ï¼Œé¿å…ä¾èµ–é—®é¢˜
  const speakRef = useRef(speak)
  const autoSpeakRef = useRef(autoSpeak)
  const synthesisSettingsRef = useRef(speechSettings)
  
  // æ›´æ–°refs
  useEffect(() => {
    speakRef.current = speak
    autoSpeakRef.current = autoSpeak
    synthesisSettingsRef.current = speechSettings
  })

  // ç›‘å¬AIå›å¤ - åªè®¾ç½®ä¸€æ¬¡å›è°ƒï¼Œé¿å…é‡å¤è¯·æ±‚
  useEffect(() => {
    const handleNewAIResponse = (response: string) => {
      console.log('ğŸµ VoiceChatInput æ”¶åˆ°AIå›å¤å›è°ƒ:', {
        response: response.slice(0, 50) + '...',
        responseLength: response.length,
        timestamp: new Date().toISOString()
      })
      
      // é˜²é‡å¤å¤„ç†ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€ä¸ªå›å¤
      if (lastProcessedResponseRef.current === response) {
        console.log('âš ï¸ é‡å¤çš„AIå›å¤ï¼Œè·³è¿‡å¤„ç†')
        return
      }
      
      // è®°å½•å·²å¤„ç†çš„å›å¤
      lastProcessedResponseRef.current = response
      
      // ä¿å­˜æœ€æ–°çš„AIå›å¤
      setLastAIResponse(response)
      
      // ä½¿ç”¨refè·å–æœ€æ–°å€¼ï¼Œé¿å…é—­åŒ…é—®é¢˜
      const currentAutoSpeak = autoSpeakRef.current
      const currentSettings = synthesisSettingsRef.current
      const currentSpeak = speakRef.current
      
      // å¦‚æœå¯ç”¨äº†è‡ªåŠ¨æ’­æ”¾ä¸”æµè§ˆå™¨æ”¯æŒè¯­éŸ³åˆæˆï¼Œåˆ™è‡ªåŠ¨æ’­æ”¾
      if (currentAutoSpeak && synthesisSupported && currentSettings.voiceEnabled) {
        console.log('ğŸ”Š è‡ªåŠ¨å¼€å§‹Qwen-TTSè¯­éŸ³åˆæˆæ’­æ”¾')
        try {
          currentSpeak(response)
          console.log('âœ… è‡ªåŠ¨è¯­éŸ³åˆæˆè°ƒç”¨æˆåŠŸ')
        } catch (error) {
          console.error('âŒ è‡ªåŠ¨è¯­éŸ³åˆæˆå¤±è´¥:', error)
        }
      } else {
        console.log('ğŸ“ AIå›å¤å·²ä¿å­˜ï¼Œè‡ªåŠ¨æ’­æ”¾å·²ç¦ç”¨')
      }
    }
    
    console.log('ğŸ“ è®¾ç½®AIå›å¤è‡ªåŠ¨æ’­æ”¾å›è°ƒï¼ˆä¸€æ¬¡æ€§ï¼‰')
    setOnNewAIResponse(handleNewAIResponse)
    
    // æ¸…ç†å‡½æ•°
    return () => {
      console.log('ğŸ§¹ æ¸…ç†AIå›å¤è‡ªåŠ¨æ’­æ”¾å›è°ƒ')
      setOnNewAIResponse(() => {})
    }
  }, [setOnNewAIResponse, synthesisSupported]) // åªä¿ç•™å¿…è¦çš„ä¾èµ–

  // æ‰‹åŠ¨æ’­æ”¾æœ€æ–°AIå›å¤ - åœ¨ç”¨æˆ·ç‚¹å‡»äº‹ä»¶ä¸­ç›´æ¥è°ƒç”¨
  const handleManualPlay = () => {
    console.log('ğŸ¯ ç”¨æˆ·ç‚¹å‡»æ’­æ”¾æŒ‰é’®', {
      hasLastResponse: !!lastAIResponse,
      isSpeaking,
      synthesisSupported,
      hasError: !!synthesisError
    })

    if (isSpeaking) {
      console.log('ğŸ›‘ åœæ­¢å½“å‰æ’­æ”¾')
      stopSpeaking()
      return
    }

    if (!lastAIResponse) {
      console.log('âš ï¸ æ²¡æœ‰å¯æ’­æ”¾çš„AIå›å¤')
      return
    }

    if (!synthesisSupported) {
      console.error('âŒ æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆ')
      return
    }

    console.log('ğŸµ å¼€å§‹æ‰‹åŠ¨æ’­æ”¾AIå›å¤:', {
      text: lastAIResponse.slice(0, 50) + '...',
      length: lastAIResponse.length
    })

    // åœ¨ç”¨æˆ·ç‚¹å‡»äº‹ä»¶ä¸­ç«‹å³è°ƒç”¨è¯­éŸ³åˆæˆï¼Œè¿™æ ·æœ‰æœ€å¤§çš„æˆåŠŸæ¦‚ç‡
    try {
      speak(lastAIResponse)
      console.log('âœ… è¯­éŸ³åˆæˆè°ƒç”¨æˆåŠŸ')
    } catch (error) {
      console.error('âŒ æ‰‹åŠ¨æ’­æ”¾å¤±è´¥:', error)
    }
  }

  const currentTranscript = finalTranscript + interimTranscript

  // æ¸²æŸ“å‰çš„æœ€ç»ˆçŠ¶æ€æ£€æŸ¥
  console.log('ğŸ–¼ï¸ VoiceChatInput å³å°†æ¸²æŸ“:', {
    isVoiceMode,
    recognitionSupported,
    disabled,
    isListening,
    hasError: !!recognitionError,
    timestamp: new Date().toISOString()
  })

  return (
    <div className="space-y-4">
      {/* é”™è¯¯æç¤º */}
      <AnimatePresence>
        {(recognitionError || synthesisError) && (
          <motion.div
            initial={{ opacity: 0, height: 0 }}
            animate={{ opacity: 1, height: 'auto' }}
            exit={{ opacity: 0, height: 0 }}
            className="bg-red-50 border border-red-200 rounded-lg p-3"
          >
            <p className="text-red-700 text-sm">
              âš ï¸ {recognitionError || synthesisError}
            </p>
          </motion.div>
        )}
      </AnimatePresence>

      {/* è¯­éŸ³çŠ¶æ€æ˜¾ç¤º */}
      <AnimatePresence>
        {isVoiceMode && (isListening || isSpeaking || currentTranscript) && (
          <motion.div
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            exit={{ opacity: 0, y: -10 }}
            className="bg-gradient-to-r from-blue-50 to-purple-50 rounded-xl p-4 border border-blue-200"
          >
            <div className="flex items-center justify-between mb-3">
              <div className="flex items-center space-x-2">
                <div className={`w-3 h-3 rounded-full ${
                  isListening ? 'bg-red-500 animate-pulse' : 
                  isSpeaking ? 'bg-green-500 animate-pulse' : 'bg-gray-400'
                }`} />
                <span className="text-sm font-medium text-gray-700">
                  {isListening ? 'æ­£åœ¨å¬å–æ‚¨çš„è¯è¯­...' : 
                   isSpeaking ? 'æ­£åœ¨æ’­æ”¾å›å¤...' : 
                   currentTranscript ? 'è¯†åˆ«å®Œæˆ' : 'ç­‰å¾…ä¸­'}
                </span>
              </div>
              
              <AudioVisualizer
                isActive={isListening || isSpeaking}
                type={isListening ? 'recording' : 'speaking'}
                size="small"
              />
            </div>
            
            {/* å®æ—¶è½¬å½•æ˜¾ç¤º */}
            {currentTranscript && (
              <div className="bg-white rounded-lg p-3 text-sm">
                <span className="text-gray-500">è¯†åˆ«ç»“æœï¼š</span>
                <span className="text-gray-800 ml-2">
                  {finalTranscript}
                  <span className="text-gray-400">{interimTranscript}</span>
                </span>
              </div>
            )}
          </motion.div>
        )}
      </AnimatePresence>

      {/* ä¸»è¾“å…¥åŒºåŸŸ */}
      <div className="relative">
        <div className={`flex items-end space-x-3 p-4 bg-white rounded-2xl shadow-lg border-2 transition-all duration-200 ${
          disabled 
            ? 'border-gray-200 bg-gray-50' 
            : isVoiceMode 
              ? 'border-blue-300 bg-gradient-to-r from-blue-50 to-purple-50'
              : 'border-gray-200 focus-within:border-blue-300'
        }`}>
          
          {/* æ¨¡å¼åˆ‡æ¢æŒ‰é’® */}
          <motion.button
            whileHover={{ scale: 1.05 }}
            whileTap={{ scale: 0.95 }}
            onClick={toggleVoiceMode}
            disabled={disabled}
            className={`flex-shrink-0 p-3 rounded-xl transition-all duration-200 ${
              isVoiceMode 
                ? 'bg-blue-500 text-white shadow-lg' 
                : 'bg-gray-100 text-gray-600 hover:bg-gray-200'
            } disabled:opacity-50 disabled:cursor-not-allowed`}
            title={isVoiceMode ? 'åˆ‡æ¢åˆ°æ–‡å­—è¾“å…¥' : 'åˆ‡æ¢åˆ°è¯­éŸ³è¾“å…¥'}
          >
            {isVoiceMode ? <Mic className="w-5 h-5" /> : <Keyboard className="w-5 h-5" />}
          </motion.button>

          {/* è¾“å…¥åŒºåŸŸ */}
          <div className="flex-1">
            {isVoiceMode ? (
              // è¯­éŸ³æ¨¡å¼
              <div className="flex items-center justify-center py-4">
                <button
                  onClick={(e) => {
                    console.log('ğŸ¯ åŸç”ŸæŒ‰é’®ç‚¹å‡»äº‹ä»¶è§¦å‘!', e)
                    e.preventDefault()
                    e.stopPropagation()
                    handleMicClick()
                  }}
                  onMouseDown={(e) => {
                    console.log('ğŸ–±ï¸ åŸç”ŸæŒ‰é’®é¼ æ ‡æŒ‰ä¸‹äº‹ä»¶è§¦å‘', e)
                  }}
                  onPointerDown={(e) => {
                    console.log('ğŸ‘† åŸç”ŸæŒ‰é’®æŒ‡é’ˆæŒ‰ä¸‹äº‹ä»¶è§¦å‘', e)
                  }}
                  disabled={disabled || !recognitionSupported}
                  className={`p-6 rounded-full transition-all duration-200 cursor-pointer relative ${
                    isListening 
                      ? 'bg-red-500 text-white shadow-xl scale-110' 
                      : 'bg-blue-500 text-white hover:bg-blue-600 shadow-lg'
                  } disabled:opacity-50 disabled:cursor-not-allowed`}
                  style={{
                    zIndex: 10,
                    position: 'relative',
                    pointerEvents: 'auto'
                  }}
                >
                  {isListening ? <MicOff className="w-8 h-8" /> : <Mic className="w-8 h-8" />}
                </button>
              </div>
            ) : (
              // æ–‡å­—æ¨¡å¼
              <textarea
                ref={textareaRef}
                value={textInput}
                onChange={handleInputChange}
                onKeyDown={handleKeyDown}
                placeholder={placeholder}
                disabled={disabled}
                rows={1}
                className="w-full resize-none border-none outline-none bg-transparent text-gray-800 placeholder-gray-400 disabled:cursor-not-allowed disabled:text-gray-500"
                style={{ 
                  minHeight: '24px',
                  maxHeight: '120px',
                  lineHeight: '24px'
                }}
              />
            )}
          </div>

          {/* æ§åˆ¶æŒ‰é’®ç»„ */}
          <div className="flex items-center space-x-2">
            {/* è¯­éŸ³æ’­æ”¾æ§åˆ¶ - æ”¯æŒæ‰‹åŠ¨æ’­æ”¾AIå›å¤ */}
            {synthesisSupported && (
              <div className="flex items-center space-x-1">
                <motion.button
                  whileHover={{ scale: 1.05 }}
                  whileTap={{ scale: 0.95 }}
                  onClick={handleManualPlay}
                  disabled={disabled || (!lastAIResponse && !isSpeaking && !isSynthesisLoading)}
                  className={`p-2 rounded-lg transition-all duration-200 ${
                    isSpeaking 
                      ? 'bg-red-500 text-white hover:bg-red-600' 
                      : isSynthesisLoading
                        ? 'bg-yellow-500 text-white'
                        : lastAIResponse 
                          ? 'bg-green-500 text-white hover:bg-green-600'
                          : 'bg-gray-100 text-gray-400'
                  } disabled:opacity-50 disabled:cursor-not-allowed`}
                  title={
                    isSpeaking 
                      ? 'åœæ­¢æ’­æ”¾' 
                      : isSynthesisLoading
                        ? 'æ­£åœ¨å®æ—¶åˆæˆè¯­éŸ³...'
                        : lastAIResponse 
                          ? 'æ’­æ”¾AIå›å¤ (Qwen-TTS Realtime)' 
                          : 'æš‚æ— å¯æ’­æ”¾å†…å®¹'
                  }
                >
                  {isSpeaking ? (
                    <VolumeX className="w-4 h-4" />
                  ) : isSynthesisLoading ? (
                    <div className="w-4 h-4 border-2 border-white border-t-transparent rounded-full animate-spin" />
                  ) : (
                    <Volume2 className="w-4 h-4" />
                  )}
                </motion.button>
                
                {/* çŠ¶æ€æç¤º */}
                {synthesisError && synthesisError.includes('æµè§ˆå™¨é˜»æ­¢') && (
                  <span className="text-xs text-orange-600 whitespace-nowrap">
                    ğŸ‘†ç‚¹å‡»æ’­æ”¾
                  </span>
                )}
                
                {synthesisError && synthesisError.includes('canceled') && (
                  <span className="text-xs text-blue-600 whitespace-nowrap">
                    æ‰‹åŠ¨æ’­æ”¾
                  </span>
                )}
                
                {isSynthesisLoading && (
                  <span className="text-xs text-yellow-600 whitespace-nowrap">
                    å®æ—¶åˆæˆ...
                  </span>
                )}
                
                {isSpeaking && !isSynthesisLoading && (
                  <span className="text-xs text-red-600 whitespace-nowrap">
                    æ’­æ”¾ä¸­...
                  </span>
                )}
                
                {lastAIResponse && !isSpeaking && !isSynthesisLoading && !synthesisError && (
                  <span className="text-xs text-green-600 whitespace-nowrap">
                    Realtime
                  </span>
                )}
                
                {!lastAIResponse && !isSpeaking && !isSynthesisLoading && (
                  <span className="text-xs text-gray-400 whitespace-nowrap">
                    ç­‰å¾…å›å¤
                  </span>
                )}
                
                {process.env.NODE_ENV === 'development' && (
                  <span className="text-xs text-gray-500 whitespace-nowrap ml-2">
                    Debug: {isSpeaking ? 'playing' : 'idle'}
                  </span>
                )}
              </div>
            )}

            {/* è®¾ç½®æŒ‰é’® */}
            <motion.button
              whileHover={{ scale: 1.05 }}
              whileTap={{ scale: 0.95 }}
              onClick={() => setShowSettings(!showSettings)}
              disabled={disabled}
              className="p-2 text-gray-400 hover:text-gray-600 rounded-lg hover:bg-gray-100 transition-colors disabled:opacity-50 disabled:cursor-not-allowed"
              title="è¯­éŸ³è®¾ç½®"
            >
              <Settings className="w-4 h-4" />
            </motion.button>

            {/* å‘é€æŒ‰é’®ï¼ˆæ–‡å­—æ¨¡å¼ï¼‰ */}
            {!isVoiceMode && (
              <motion.button
                whileHover={!disabled ? { scale: 1.05 } : {}}
                whileTap={!disabled ? { scale: 0.95 } : {}}
                onClick={handleTextSubmit}
                disabled={disabled || !textInput.trim()}
                className={`flex-shrink-0 p-2 rounded-xl transition-all duration-200 ${
                  disabled || !textInput.trim()
                    ? 'bg-gray-200 text-gray-400 cursor-not-allowed'
                    : 'bg-blue-500 text-white hover:bg-blue-600 shadow-lg'
                }`}
                title="å‘é€æ¶ˆæ¯ (Enter)"
              >
                <Send className="w-5 h-5" />
              </motion.button>
            )}
          </div>
        </div>

        {/* åŠŸèƒ½æç¤º */}
        <div className="mt-3 flex items-center justify-between text-xs text-gray-500">
          <div className="flex items-center space-x-4">
            <span>
              {isVoiceMode 
                ? `ğŸ¤ ${recognitionSupported ? 'ç‚¹å‡»éº¦å…‹é£å¼€å§‹å½•éŸ³' : 'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«'}` 
                : 'ğŸ’¡ æŒ‰ Enter å‘é€ï¼ŒShift + Enter æ¢è¡Œ'
              }
            </span>
          </div>
          <div className="flex items-center space-x-2">
            <div className={`w-2 h-2 rounded-full ${
              disabled ? 'bg-red-500' : 'bg-green-500'
            }`} />
            <span>{disabled ? 'è¿æ¥ä¸­' : 'å·²è¿æ¥'}</span>
          </div>
        </div>
      </div>

      {/* è®¾ç½®é¢æ¿ */}
      <AnimatePresence>
        {showSettings && (
          <motion.div
            initial={{ opacity: 0, height: 0 }}
            animate={{ opacity: 1, height: 'auto' }}
            exit={{ opacity: 0, height: 0 }}
            className="bg-white rounded-xl border border-gray-200 p-4 space-y-4"
          >
            <h3 className="font-medium text-gray-800 mb-3">è¯­éŸ³è®¾ç½®</h3>
            
            {/* è¯­éŸ³å¼€å…³ */}
            <div className="flex items-center justify-between">
              <label className="text-sm text-gray-600">è‡ªåŠ¨æ’­æ”¾AIå›å¤</label>
              <button
                onClick={() => setSpeechSettings(prev => ({
                  ...prev,
                  voiceEnabled: !prev.voiceEnabled
                }))}
                className={`relative w-12 h-6 rounded-full transition-colors ${
                  speechSettings.voiceEnabled ? 'bg-blue-500' : 'bg-gray-300'
                }`}
              >
                <div className={`absolute w-5 h-5 bg-white rounded-full transition-transform top-0.5 ${
                  speechSettings.voiceEnabled ? 'translate-x-6' : 'translate-x-0.5'
                }`} />
              </button>
            </div>

            {/* Qwen-TTS è¯­éŸ³é€‰æ‹© */}
            {speechSettings.voiceEnabled && (
              <>
                <div className="space-y-2">
                  <label className="text-sm text-gray-600">é€‰æ‹©è¯­éŸ³</label>
                  <select
                    value={speechSettings.selectedVoice}
                    onChange={(e) => setSpeechSettings(prev => ({
                      ...prev,
                      selectedVoice: e.target.value
                    }))}
                    className="w-full p-2 border border-gray-300 rounded-lg text-sm focus:outline-none focus:ring-2 focus:ring-blue-500"
                  >
                    {voices.map((voice) => (
                      <option key={voice.name} value={voice.name}>
                        {voice.name} - {voice.description} ({voice.dialect})
                      </option>
                    ))}
                    {voices.length === 0 && (
                      <option value="Cherry">Cherry - æ¸©æŸ”ç”œç¾å¥³å£° (æ ‡å‡†æ™®é€šè¯)</option>
                    )}
                  </select>
                </div>

                {/* è¯­éŸ³ä¿¡æ¯æ˜¾ç¤º */}
                <div className="text-xs text-gray-500 space-y-1">
                  <p>ğŸš€ å½“å‰ä½¿ç”¨: Qwen-TTS Realtime API</p>
                  <p>âš¡ å®æ—¶æµå¼åˆæˆï¼Œæ— éœ€ç­‰å¾…</p>
                  <p>ğŸ­ å¯ç”¨è¯­éŸ³: {voices.length > 0 ? voices.length : 'åŠ è½½ä¸­...'} ä¸ª</p>
                  <p>ğŸŒ æ”¯æŒ: ä¸­è‹±åŒè¯­ã€æ–¹è¨€ (Cherryã€Dylanã€Jadaç­‰)</p>
                </div>
              </>
            )}
          </motion.div>
        )}
      </AnimatePresence>
    </div>
  )
}

export default VoiceChatInput 