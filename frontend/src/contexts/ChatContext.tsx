import React, { createContext, useContext, useReducer, useCallback, useEffect, useRef } from 'react'
import { ChatContextType, ChatState, Message, UserPreferences } from '../types'
import { generateId, storage } from '../utils'

// åˆå§‹çŠ¶æ€
const initialState: ChatState = {
  messages: [],
  isConnected: false,
  isTyping: false,
  connectionError: null,
  sessionId: generateId(),
  userId: 'default'
}

// åˆå§‹åå¥½è®¾ç½®
const initialPreferences: UserPreferences = {
  theme: 'light',
  fontSize: 'medium',
  soundEnabled: true,
  autoScroll: true,
  showTimestamps: false
}

// Action ç±»å‹
type ChatAction =
  | { type: 'SET_CONNECTED'; payload: boolean }
  | { type: 'SET_TYPING'; payload: boolean }
  | { type: 'SET_ERROR'; payload: string | null }
  | { type: 'ADD_MESSAGE'; payload: Message }
  | { type: 'UPDATE_MESSAGE'; payload: { id: string; updates: Partial<Message> } }
  | { type: 'CLEAR_MESSAGES' }
  | { type: 'SET_MESSAGES'; payload: Message[] }

// Reducer
const chatReducer = (state: ChatState, action: ChatAction): ChatState => {
  switch (action.type) {
    case 'SET_CONNECTED':
      return { ...state, isConnected: action.payload }
    
    case 'SET_TYPING':
      return { ...state, isTyping: action.payload }
    
    case 'SET_ERROR':
      return { ...state, connectionError: action.payload }
    
    case 'ADD_MESSAGE':
      return { 
        ...state, 
        messages: [...state.messages, action.payload] 
      }
    
    case 'UPDATE_MESSAGE':
      return {
        ...state,
        messages: state.messages.map(msg =>
          msg.id === action.payload.id
            ? { ...msg, ...action.payload.updates }
            : msg
        )
      }
    
    case 'CLEAR_MESSAGES':
      return { ...state, messages: [] }
    
    case 'SET_MESSAGES':
      return { ...state, messages: action.payload }
    
    default:
      return state
  }
}

// Context
const ChatContext = createContext<ChatContextType | undefined>(undefined)

// Provider
export const ChatProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {
  const [state, dispatch] = useReducer(chatReducer, initialState)
  const [preferences, setPreferences] = React.useState<UserPreferences>(() => {
    return storage.get('chat_preferences') || initialPreferences
  })

  // WebSocket å¼•ç”¨
  const wsRef = React.useRef<WebSocket | null>(null)
  
  // è¯­éŸ³å›è°ƒå¼•ç”¨
  const onNewAIResponseRef = useRef<((response: string) => void) | null>(null)
  
  // è¯­éŸ³é˜Ÿåˆ—ç®¡ç†
  const speechQueueRef = useRef<Array<{content: string, agent?: string, audioData?: string, order?: number}>>([])
  const isSpeakingRef = useRef<boolean>(false)
  const audioBufferRef = useRef<Map<string, {chunks: Array<string>, order: number, agent_name: string}>>(new Map())
  const audioContextRef = useRef<AudioContext | null>(null)

  // è¿æ¥ WebSocket
  const connect = useCallback(() => {
    if (wsRef.current?.readyState === WebSocket.OPEN) {
      return
    }

    try {
      const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:'
      const host = process.env.NODE_ENV === 'development' 
        ? 'localhost:8000' 
        : window.location.host
      const wsUrl = `${protocol}//${host}/api/realtime/ws/${state.sessionId}`

      wsRef.current = new WebSocket(wsUrl)

      wsRef.current.onopen = () => {
        dispatch({ type: 'SET_CONNECTED', payload: true })
        dispatch({ type: 'SET_ERROR', payload: null })
        console.log('WebSocket è¿æ¥å·²å»ºç«‹')
      }

      wsRef.current.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data)
          console.log(`ğŸ“¨ WebSocketæ”¶åˆ°åŸå§‹æ¶ˆæ¯: type=${data.type}, agent_id=${data.agent_id || 'N/A'}, order=${data.order || 'N/A'}`)
          
          switch (data.type) {
            case 'welcome':
              dispatch({
                type: 'ADD_MESSAGE',
                payload: {
                  id: generateId(),
                  type: 'assistant',
                  content: data.message,
                  timestamp: data.timestamp || new Date().toISOString()
                }
              })
              break
            
            case 'multi_agent_processing_start':
              dispatch({ type: 'SET_TYPING', payload: true })
              break
            
            case 'processing':
              dispatch({
                type: 'ADD_MESSAGE',
                payload: {
                  id: 'typing',
                  type: 'assistant',
                  content: data.message,
                  timestamp: data.timestamp || new Date().toISOString(),
                  isTyping: true
                }
              })
              break
            
            case 'response':
              console.log('ğŸ¤– æ”¶åˆ°AIå›å¤:', data.message)
              
              // ç§»é™¤æ‰“å­—æŒ‡ç¤ºå™¨
              dispatch({
                type: 'SET_MESSAGES',
                payload: state.messages.filter(msg => msg.id !== 'typing')
              })
              
              // æ·»åŠ å›å¤
              dispatch({
                type: 'ADD_MESSAGE',
                payload: {
                  id: generateId(),
                  type: 'assistant',
                  content: data.message,
                  timestamp: data.timestamp || new Date().toISOString(),
                  retrievedDocs: data.retrieved_docs,
                  context: data.context
                }
              })
              
              // è§¦å‘è¯­éŸ³å›è°ƒ
              if (onNewAIResponseRef.current && data.message) {
                console.log('ğŸ”Š è§¦å‘è¯­éŸ³åˆæˆå›è°ƒ:', {
                  hasCallback: !!onNewAIResponseRef.current,
                  messageLength: data.message.length,
                  messagePreview: data.message.slice(0, 50) + '...'
                })
                onNewAIResponseRef.current(data.message)
              } else {
                console.log('âš ï¸ è¯­éŸ³åˆæˆå›è°ƒæœªè®¾ç½®æˆ–æ¶ˆæ¯ä¸ºç©º:', {
                  hasCallback: !!onNewAIResponseRef.current,
                  hasMessage: !!data.message
                })
              }
              break
            
            case 'multi_agent_response':
              console.log('ğŸ¤– æ”¶åˆ°å¤šæ™ºèƒ½ä½“å›å¤:', data)
              console.log(`ğŸ“Š æ™ºèƒ½ä½“ä¿¡æ¯: ID=${data.agent_id}, Name=${data.agent_name}, Order=${data.order}`)
              console.log(`ğŸ”¢ å½“å‰æ¶ˆæ¯æ€»æ•°: ${state.messages.length}`)
              
              // åªæœ‰æ”¶åˆ°ç¬¬ä¸€ä¸ªå›å¤æ—¶åœæ­¢æ‰“å­—æŒ‡ç¤ºå™¨
              if (data.order === 1) {
                dispatch({ type: 'SET_TYPING', payload: false })
                console.log('â¹ï¸ åœæ­¢æ‰“å­—æŒ‡ç¤ºå™¨ (ç¬¬ä¸€ä¸ªå›å¤)')
              }
              
              dispatch({
                type: 'ADD_MESSAGE',
                payload: {
                  id: generateId(),
                  type: data.agent_id as 'buffett' | 'soros' | 'munger',
                  content: data.content,
                  timestamp: data.timestamp || new Date().toISOString(),
                  agent_id: data.agent_id,
                  agent_name: data.agent_name,
                  order: data.order,
                  isMultiAgent: true,
                  agent: {
                    id: data.agent_id,
                    name: data.agent_name || 'æœªçŸ¥æ™ºèƒ½ä½“',
                    description: data.agent_id === 'buffett' ? 'ä»·å€¼æŠ•èµ„å¤§å¸ˆ' : 
                                data.agent_id === 'soros' ? 'å®è§‚æŠ•èµ„å¤§å¸ˆ' : 'å¤šå…ƒæ€ç»´ä¸“å®¶',
                    color: data.agent_id === 'buffett' ? '#3B82F6' : 
                           data.agent_id === 'soros' ? '#10B981' : '#8B5CF6'
                  }
                }
              })
              
              // å¤šæ™ºèƒ½ä½“æ–‡æœ¬å›å¤ï¼šä¸å†ç›´æ¥åˆæˆè¯­éŸ³ï¼Œç­‰å¾…åç«¯å‘é€éŸ³é¢‘
              console.log('ğŸ“ æ”¶åˆ°å¤šæ™ºèƒ½ä½“æ–‡æœ¬ï¼Œç­‰å¾…åç«¯éŸ³é¢‘æ•°æ®...')
              break
            
            case 'multi_agent_audio_chunk':
              // æ”¶é›†éŸ³é¢‘å—
              const audioKey = `${data.agent_id}_${data.order}`
              const audioBuffer = audioBufferRef.current.get(audioKey) || {
                chunks: [] as string[],
                order: data.order,
                agent_name: data.agent_name
              }
              audioBuffer.chunks.push(data.audio_data as string)
              audioBufferRef.current.set(audioKey, audioBuffer)
              console.log(`ğŸµ æ”¶åˆ°éŸ³é¢‘å—: ${data.agent_name}, chunk ${data.chunk_index}`)
              break
            
            case 'multi_agent_tts_complete':
              // TTSå®Œæˆï¼Œå°†å®Œæ•´éŸ³é¢‘åŠ å…¥æ’­æ”¾é˜Ÿåˆ—
              const completeAudioKey = `${data.agent_id}_${data.order}`
              const completeAudioBuffer = audioBufferRef.current.get(completeAudioKey)
              
              if (completeAudioBuffer) {
                // åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
                const fullAudioData = completeAudioBuffer.chunks.join('')
                console.log(`âœ… TTSå®Œæˆï¼ŒåŠ å…¥æ’­æ”¾é˜Ÿåˆ—: ${data.agent_name}, order=${data.order}`)
                
                // ç›´æ¥åŠ å…¥è¯­éŸ³æ’­æ”¾é˜Ÿåˆ—ï¼ˆå·²ç»æ˜¯å®Œæ•´éŸ³é¢‘ï¼‰
                speechQueueRef.current.push({
                  content: '', // æ–‡æœ¬å†…å®¹ä¸éœ€è¦äº†
                  agent: data.agent_name,
                  audioData: fullAudioData,
                  order: data.order
                })
                
                // æŒ‰orderæ’åºç¡®ä¿æ’­æ”¾é¡ºåº
                speechQueueRef.current.sort((a, b) => (a.order || 0) - (b.order || 0))
                
                // æ¸…ç†ç¼“å­˜
                audioBufferRef.current.delete(completeAudioKey)
                
                console.log(`ğŸ“‹ è¯­éŸ³é˜Ÿåˆ—çŠ¶æ€:`, speechQueueRef.current.map(s => ({
                  agent: s.agent,
                  order: s.order,
                  hasAudio: !!s.audioData
                })))
                
                // è§¦å‘æ’­æ”¾é˜Ÿåˆ—å¤„ç†
                processSpeechQueue()
              }
              break
            
            case 'error':
              dispatch({ type: 'SET_ERROR', payload: data.message })
              break
          }
        } catch (error) {
          console.error('å¤„ç† WebSocket æ¶ˆæ¯å¤±è´¥:', error)
        }
      }

      wsRef.current.onclose = () => {
        dispatch({ type: 'SET_CONNECTED', payload: false })
        console.log('WebSocket è¿æ¥å·²å…³é—­')
        
        // è‡ªåŠ¨é‡è¿ï¼ˆå»¶è¿Ÿ 3 ç§’ï¼‰
        setTimeout(() => {
          if (wsRef.current?.readyState !== WebSocket.OPEN) {
            connect()
          }
        }, 3000)
      }

      wsRef.current.onerror = (error) => {
        console.error('WebSocket é”™è¯¯:', error)
        dispatch({ type: 'SET_ERROR', payload: 'WebSocket è¿æ¥é”™è¯¯' })
      }

    } catch (error) {
      console.error('åˆ›å»º WebSocket è¿æ¥å¤±è´¥:', error)
      dispatch({ type: 'SET_ERROR', payload: 'è¿æ¥å¤±è´¥' })
    }
  }, [state.sessionId])

  // æ–­å¼€è¿æ¥
  const disconnect = useCallback(() => {
    if (wsRef.current) {
      wsRef.current.close()
      wsRef.current = null
    }
    dispatch({ type: 'SET_CONNECTED', payload: false })
  }, [])

  // å‘é€æ¶ˆæ¯
  const sendMessage = useCallback(async (content: string) => {
    console.log('ğŸ“¨ ChatContext sendMessage è¢«è°ƒç”¨:', content)
    
    if (!content.trim()) {
      console.log('âš ï¸ ç©ºæ¶ˆæ¯è¢«å¿½ç•¥')
      return
    }

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    const userMessage: Message = {
      id: generateId(),
      type: 'user',
      content: content.trim(),
      timestamp: new Date().toISOString()
    }

    console.log('â• æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°èŠå¤©:', userMessage)
    dispatch({ type: 'ADD_MESSAGE', payload: userMessage })

    // é€šè¿‡ WebSocket å‘é€
    const wsState = wsRef.current?.readyState
    console.log('ğŸ”Œ WebSocket çŠ¶æ€:', {
      state: wsState,
      isOpen: wsState === WebSocket.OPEN,
      CONNECTING: WebSocket.CONNECTING,
      OPEN: WebSocket.OPEN,
      CLOSING: WebSocket.CLOSING,
      CLOSED: WebSocket.CLOSED
    })

    if (wsRef.current?.readyState === WebSocket.OPEN) {
      try {
        const messageData = {
          type: "chat",
          message: content.trim(),
          user_id: state.userId,
          session_id: state.sessionId,
          chat_mode: "multi_agent"
        }
        console.log('ğŸ“¤ å‘é€ WebSocket æ¶ˆæ¯:', messageData)
        console.log(`ğŸ†” ä½¿ç”¨çš„ SessionID: ${state.sessionId}`)
        console.log(`ğŸ”— WebSocket URL: ${wsRef.current?.url}`)
        wsRef.current.send(JSON.stringify(messageData))
        console.log('âœ… WebSocket æ¶ˆæ¯å‘é€æˆåŠŸ')
      } catch (error) {
        console.error('âŒ å‘é€æ¶ˆæ¯å¤±è´¥:', error)
        dispatch({ type: 'SET_ERROR', payload: 'å‘é€æ¶ˆæ¯å¤±è´¥' })
      }
    } else {
      console.log('ğŸ”„ WebSocket æœªè¿æ¥ï¼Œå°è¯•é‡è¿...')
      dispatch({ type: 'SET_ERROR', payload: 'è¿æ¥å·²æ–­å¼€ï¼Œæ­£åœ¨é‡æ–°è¿æ¥...' })
      connect() // å°è¯•é‡è¿
    }
  }, [state.userId, state.sessionId, connect])

  // æ¸…ç©ºèŠå¤©
  const clearChat = useCallback(() => {
    dispatch({ type: 'CLEAR_MESSAGES' })
    // å¯ä»¥åœ¨è¿™é‡Œè°ƒç”¨ API æ¸…ç©ºæœåŠ¡ç«¯çš„å¯¹è¯å†å²
  }, [])

  // æ›´æ–°åå¥½è®¾ç½®
  const updatePreferences = useCallback((newPreferences: Partial<UserPreferences>) => {
    const updated = { ...preferences, ...newPreferences }
    setPreferences(updated)
    storage.set('chat_preferences', updated)
  }, [preferences])

  // å¤„ç†è¯­éŸ³é˜Ÿåˆ—
  const processSpeechQueue = useCallback(() => {
    if (isSpeakingRef.current || speechQueueRef.current.length === 0) {
      return
    }
    
    const nextSpeech = speechQueueRef.current.shift()
    if (nextSpeech) {
      isSpeakingRef.current = true
      console.log('ğŸµ å¼€å§‹æ’­æ”¾è¯­éŸ³é˜Ÿåˆ—:', {
        agent: nextSpeech.agent || 'æœªçŸ¥',
        hasAudioData: !!nextSpeech.audioData,
        contentLength: nextSpeech.content.length,
        queueLength: speechQueueRef.current.length
      })
      
      if (nextSpeech.audioData) {
        // ç›´æ¥æ’­æ”¾é¢„åˆæˆçš„éŸ³é¢‘æ•°æ®
        playAudioData(nextSpeech.audioData)
      } else if (onNewAIResponseRef.current && nextSpeech.content) {
        // å›é€€åˆ°æ–‡æœ¬åˆæˆæ’­æ”¾
        onNewAIResponseRef.current(nextSpeech.content)
      }
    }
  }, [])
  
  // æ³¨é‡Šï¼šaddToSpeechQueue å·²ç§»é™¤ï¼Œæ”¹ä¸ºç›´æ¥åœ¨multi_agent_tts_completeä¸­å¤„ç†
  
  // è¯­éŸ³æ’­æ”¾å®Œæˆå›è°ƒ
  const onSpeechEnd = useCallback(() => {
    isSpeakingRef.current = false
    console.log('âœ… è¯­éŸ³æ’­æ”¾å®Œæˆï¼Œç»§ç»­å¤„ç†é˜Ÿåˆ—')
    processSpeechQueue()
  }, [processSpeechQueue])
  
  // ç›´æ¥æ’­æ”¾éŸ³é¢‘æ•°æ®
  const playAudioData = useCallback(async (base64AudioData: string) => {
    try {
      console.log('ğŸµ å¼€å§‹æ’­æ”¾é¢„åˆæˆéŸ³é¢‘æ•°æ®ï¼ˆPCMæ ¼å¼ï¼‰')
      
      // åˆå§‹åŒ–AudioContext
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)()
      }
      
      const audioContext = audioContextRef.current
      
      // Base64 è§£ç ä¸º ArrayBuffer
      const binaryString = atob(base64AudioData)
      const bytes = new Uint8Array(binaryString.length)
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i)
      }
      
      // Qwen TTS è¿”å›çš„æ˜¯PCMæ•°æ®ï¼Œéœ€è¦è½¬æ¢ä¸ºAudioBuffer
      // éŸ³é¢‘å‚æ•°ï¼š24kHz, 16-bit, mono
      const sampleRate = 24000
      const numChannels = 1
      const bytesPerSample = 2 // 16-bit = 2 bytes
      
      // è®¡ç®—é‡‡æ ·ç‚¹æ•°é‡
      const numSamples = bytes.length / bytesPerSample
      
      // åˆ›å»ºAudioBuffer
      const audioBuffer = audioContext.createBuffer(numChannels, numSamples, sampleRate)
      const channelData = audioBuffer.getChannelData(0)
      
      // å°†16-bit PCMæ•°æ®è½¬æ¢ä¸ºæµ®ç‚¹æ•° (-1.0 åˆ° 1.0)
      for (let i = 0; i < numSamples; i++) {
        const byteIndex = i * bytesPerSample
        // è¯»å–16-bit little-endian
        const sample = (bytes[byteIndex + 1] << 8) | bytes[byteIndex]
        // è½¬æ¢ä¸ºæœ‰ç¬¦å·16-bit
        const signedSample = sample > 32767 ? sample - 65536 : sample
        // å½’ä¸€åŒ–åˆ° -1.0 åˆ° 1.0
        channelData[i] = signedSample / 32768.0
      }
      
      // åˆ›å»ºéŸ³é¢‘æº
      const source = audioContext.createBufferSource()
      source.buffer = audioBuffer
      source.connect(audioContext.destination)
      
      // æ’­æ”¾ç»“æŸåçš„å¤„ç†
      source.onended = () => {
        console.log('âœ… é¢„åˆæˆéŸ³é¢‘æ’­æ”¾å®Œæˆ')
        isSpeakingRef.current = false
        processSpeechQueue() // ç»§ç»­æ’­æ”¾é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€ä¸ª
      }
      
      // å¼€å§‹æ’­æ”¾
      source.start(0)
      console.log('ğŸµ é¢„åˆæˆéŸ³é¢‘å¼€å§‹æ’­æ”¾ï¼Œé‡‡æ ·æ•°:', numSamples)
      
    } catch (error) {
      console.error('âŒ æ’­æ”¾é¢„åˆæˆéŸ³é¢‘å¤±è´¥:', error)
      isSpeakingRef.current = false
      processSpeechQueue() // ç»§ç»­å¤„ç†é˜Ÿåˆ—
    }
  }, [])

  // è®¾ç½®æ–°AIå›å¤çš„å›è°ƒ
  const setOnNewAIResponse = useCallback((callback: (response: string) => void) => {
    onNewAIResponseRef.current = callback
  }, [])

  // åˆå§‹åŒ–è¿æ¥
  useEffect(() => {
    connect()
    
    return () => {
      disconnect()
    }
  }, [])

  // ç›‘å¬æ¶ˆæ¯å˜åŒ–ä»¥æ”¯æŒè‡ªåŠ¨æ»šåŠ¨
  useEffect(() => {
    if (preferences.autoScroll && state.messages.length > 0) {
      // å»¶è¿Ÿä¸€ç‚¹æ—¶é—´ä»¥ç¡®ä¿ DOM æ›´æ–°
      setTimeout(() => {
        const chatContainer = document.querySelector('[data-chat-container]')
        if (chatContainer) {
          chatContainer.scrollTop = chatContainer.scrollHeight
        }
      }, 100)
    }
  }, [state.messages, preferences.autoScroll])

  const contextValue: ChatContextType = {
    state,
    sendMessage,
    clearChat,
    connect,
    disconnect,
    preferences,
    updatePreferences,
    onNewAIResponse: onNewAIResponseRef.current || undefined,
    setOnNewAIResponse,
    onSpeechEnd
  }

  return (
    <ChatContext.Provider value={contextValue}>
      {children}
    </ChatContext.Provider>
  )
}

// Hook
export const useChat = (): ChatContextType => {
  const context = useContext(ChatContext)
  if (!context) {
    throw new Error('useChat must be used within a ChatProvider')
  }
  return context
} 