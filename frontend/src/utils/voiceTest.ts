// è¯­éŸ³åŠŸèƒ½æ£€æµ‹å’Œæµ‹è¯•å·¥å…·

interface VoiceCapabilities {
  speechRecognition: boolean
  speechSynthesis: boolean
  webAudio: boolean
  mediaDevices: boolean
  userAgent: string
  browserInfo: {
    name: string
    version: string
    isSecure: boolean
  }
}

interface VoiceTestResult {
  success: boolean
  error?: string
  details?: any
}

/**
 * æ£€æµ‹æµè§ˆå™¨è¯­éŸ³åŠŸèƒ½æ”¯æŒæƒ…å†µ
 */
export function detectVoiceCapabilities(): VoiceCapabilities {
  const userAgent = navigator.userAgent
  
  // æ£€æµ‹æµè§ˆå™¨ä¿¡æ¯
  const getBrowserInfo = () => {
    let name = 'Unknown'
    let version = ''
    
    if (userAgent.includes('Chrome')) {
      name = 'Chrome'
      const match = userAgent.match(/Chrome\/(\d+)/)
      version = match ? match[1] : ''
    } else if (userAgent.includes('Firefox')) {
      name = 'Firefox' 
      const match = userAgent.match(/Firefox\/(\d+)/)
      version = match ? match[1] : ''
    } else if (userAgent.includes('Safari') && !userAgent.includes('Chrome')) {
      name = 'Safari'
      const match = userAgent.match(/Version\/(\d+)/)
      version = match ? match[1] : ''
    } else if (userAgent.includes('Edge')) {
      name = 'Edge'
      const match = userAgent.match(/Edge\/(\d+)/)
      version = match ? match[1] : ''
    }
    
    return {
      name,
      version,
      isSecure: location.protocol === 'https:' || location.hostname === 'localhost'
    }
  }

  return {
    speechRecognition: !!(window.SpeechRecognition || window.webkitSpeechRecognition),
    speechSynthesis: !!(window.speechSynthesis && window.SpeechSynthesisUtterance),
    webAudio: !!(window.AudioContext || (window as any).webkitAudioContext),
    mediaDevices: !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia),
    userAgent,
    browserInfo: getBrowserInfo()
  }
}

/**
 * æµ‹è¯•è¯­éŸ³è¯†åˆ«åŠŸèƒ½
 */
export async function testSpeechRecognition(): Promise<VoiceTestResult> {
  try {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
    
    if (!SpeechRecognition) {
      return {
        success: false,
        error: 'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«API'
      }
    }

    const recognition = new SpeechRecognition()
    recognition.lang = 'zh-CN'
    recognition.continuous = false
    recognition.interimResults = false

    return new Promise((resolve) => {
      const timeout = setTimeout(() => {
        recognition.stop()
        resolve({
          success: false,
          error: 'è¯­éŸ³è¯†åˆ«æµ‹è¯•è¶…æ—¶'
        })
      }, 5000)

      recognition.onstart = () => {
        clearTimeout(timeout)
        recognition.stop()
        resolve({
          success: true,
          details: {
            lang: recognition.lang,
            continuous: recognition.continuous,
            interimResults: recognition.interimResults
          }
        })
      }

      recognition.onerror = (event: any) => {
        clearTimeout(timeout)
        resolve({
          success: false,
          error: `è¯­éŸ³è¯†åˆ«é”™è¯¯: ${event.error}`,
          details: event
        })
      }

      try {
        recognition.start()
      } catch (error) {
        clearTimeout(timeout)
        resolve({
          success: false,
          error: `å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error}`,
          details: error
        })
      }
    })
  } catch (error) {
    return {
      success: false,
      error: `è¯­éŸ³è¯†åˆ«æµ‹è¯•å¼‚å¸¸: ${error}`,
      details: error
    }
  }
}

/**
 * æµ‹è¯•è¯­éŸ³åˆæˆåŠŸèƒ½
 */
export async function testSpeechSynthesis(): Promise<VoiceTestResult> {
  try {
    if (!window.speechSynthesis || !window.SpeechSynthesisUtterance) {
      return {
        success: false,
        error: 'æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆAPI'
      }
    }

    // ç¡®ä¿è¯­éŸ³åˆ—è¡¨å·²åŠ è½½
    const voices = window.speechSynthesis.getVoices()
    if (voices.length === 0) {
      // ç­‰å¾…è¯­éŸ³åˆ—è¡¨åŠ è½½
      await new Promise((resolve) => {
        window.speechSynthesis.onvoiceschanged = resolve
        setTimeout(resolve, 1000) // æœ€å¤šç­‰å¾…1ç§’
      })
    }

    const finalVoices = window.speechSynthesis.getVoices()
    const chineseVoices = finalVoices.filter(voice => 
      voice.lang.startsWith('zh') || voice.name.toLowerCase().includes('chinese')
    )

    // ä¸å®é™…æ’­æ”¾éŸ³é¢‘ï¼Œåªæ£€æµ‹APIå¯ç”¨æ€§
    const utterance = new SpeechSynthesisUtterance('')
    utterance.lang = 'zh-CN'
    utterance.volume = 0 // é™éŸ³æµ‹è¯•
    utterance.rate = 1
    utterance.pitch = 1

    // é€‰æ‹©åˆé€‚çš„ä¸­æ–‡è¯­éŸ³
    if (chineseVoices.length > 0) {
      utterance.voice = chineseVoices[0]
    }

    return new Promise((resolve) => {
      const timeout = setTimeout(() => {
        window.speechSynthesis.cancel()
        resolve({
          success: true, // å³ä½¿è¶…æ—¶ä¹Ÿè®¤ä¸ºæ˜¯æˆåŠŸï¼Œå› ä¸ºAPIå¯ç”¨
          details: {
            totalVoices: finalVoices.length,
            chineseVoices: chineseVoices.length,
            voiceNames: chineseVoices.map(v => v.name),
            selectedVoice: utterance.voice?.name || 'default',
            note: 'é™éŸ³æµ‹è¯•å®Œæˆï¼ŒAPIå¯ç”¨'
          }
        })
      }, 2000)

      utterance.onstart = () => {
        clearTimeout(timeout)
        // ç«‹å³åœæ­¢ï¼Œé¿å…å®é™…æ’­æ”¾
        setTimeout(() => window.speechSynthesis.cancel(), 50)
        
        resolve({
          success: true,
          details: {
            totalVoices: finalVoices.length,
            chineseVoices: chineseVoices.length,
            voiceNames: chineseVoices.map(v => v.name),
            selectedVoice: utterance.voice?.name || 'default',
            note: 'è¯­éŸ³åˆæˆå¯åŠ¨æˆåŠŸ'
          }
        })
      }

      utterance.onend = () => {
        clearTimeout(timeout)
        resolve({
          success: true,
          details: {
            totalVoices: finalVoices.length,
            chineseVoices: chineseVoices.length,
            voiceNames: chineseVoices.map(v => v.name),
            selectedVoice: utterance.voice?.name || 'default',
            note: 'è¯­éŸ³åˆæˆæ­£å¸¸ç»“æŸ'
          }
        })
      }

      utterance.onerror = (event: any) => {
        clearTimeout(timeout)
        
        // æŸäº›é”™è¯¯æ˜¯æ­£å¸¸çš„ï¼ˆæ¯”å¦‚å–æ¶ˆï¼‰ï¼Œä¸ç®—å¤±è´¥
        if (event.error === 'canceled' || event.error === 'interrupted') {
          resolve({
            success: true,
            details: {
              totalVoices: finalVoices.length,
              chineseVoices: chineseVoices.length,
              voiceNames: chineseVoices.map(v => v.name),
              selectedVoice: utterance.voice?.name || 'default',
              note: 'è¯­éŸ³åˆæˆè¢«å–æ¶ˆï¼ˆæ­£å¸¸ï¼‰'
            }
          })
        } else {
          resolve({
            success: false,
            error: `è¯­éŸ³åˆæˆé”™è¯¯: ${event.error}`,
            details: {
              ...event,
              totalVoices: finalVoices.length,
              chineseVoices: chineseVoices.length
            }
          })
        }
      }

      try {
        // å…ˆæ¸…é™¤å¯èƒ½å­˜åœ¨çš„è¯­éŸ³é˜Ÿåˆ—
        window.speechSynthesis.cancel()
        setTimeout(() => {
          window.speechSynthesis.speak(utterance)
        }, 100)
      } catch (error) {
        clearTimeout(timeout)
        resolve({
          success: false,
          error: `å¯åŠ¨è¯­éŸ³åˆæˆå¤±è´¥: ${error}`,
          details: error
        })
      }
    })
  } catch (error) {
    return {
      success: false,
      error: `è¯­éŸ³åˆæˆæµ‹è¯•å¼‚å¸¸: ${error}`,
      details: error
    }
  }
}

/**
 * æµ‹è¯•éº¦å…‹é£æƒé™
 */
export async function testMicrophoneAccess(): Promise<VoiceTestResult> {
  try {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      return {
        success: false,
        error: 'æµè§ˆå™¨ä¸æ”¯æŒmediaDevices API'
      }
    }

    const stream = await navigator.mediaDevices.getUserMedia({ 
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    })

    // è·å–éŸ³é¢‘è½¨é“ä¿¡æ¯
    const audioTracks = stream.getAudioTracks()
    const trackSettings = audioTracks[0]?.getSettings()

    // ç«‹å³åœæ­¢æµ
    stream.getTracks().forEach(track => track.stop())

    return {
      success: true,
      details: {
        tracksCount: audioTracks.length,
        trackLabel: audioTracks[0]?.label,
        settings: trackSettings
      }
    }
  } catch (error: any) {
    return {
      success: false,
      error: `éº¦å…‹é£è®¿é—®å¤±è´¥: ${error.name}: ${error.message}`,
      details: {
        name: error.name,
        message: error.message,
        code: error.code
      }
    }
  }
}

/**
 * è¿è¡Œå®Œæ•´çš„è¯­éŸ³åŠŸèƒ½æµ‹è¯•
 */
export async function runCompleteVoiceTest() {
  const capabilities = detectVoiceCapabilities()
  
  console.log('ğŸ” è¯­éŸ³åŠŸèƒ½æ£€æµ‹ç»“æœ:')
  console.log('æµè§ˆå™¨ä¿¡æ¯:', capabilities.browserInfo)
  console.log('è¯­éŸ³è¯†åˆ«æ”¯æŒ:', capabilities.speechRecognition)
  console.log('è¯­éŸ³åˆæˆæ”¯æŒ:', capabilities.speechSynthesis)
  console.log('Web Audioæ”¯æŒ:', capabilities.webAudio)
  console.log('åª’ä½“è®¾å¤‡æ”¯æŒ:', capabilities.mediaDevices)
  console.log('HTTPSå®‰å…¨è¿æ¥:', capabilities.browserInfo.isSecure)

  // æµ‹è¯•è¯­éŸ³åˆæˆ
  console.log('\nğŸ—£ï¸ æµ‹è¯•è¯­éŸ³åˆæˆ...')
  const synthesisResult = await testSpeechSynthesis()
  console.log('è¯­éŸ³åˆæˆæµ‹è¯•:', synthesisResult)

  // æµ‹è¯•éº¦å…‹é£æƒé™
  console.log('\nğŸ¤ æµ‹è¯•éº¦å…‹é£æƒé™...')
  const micResult = await testMicrophoneAccess()
  console.log('éº¦å…‹é£æƒé™æµ‹è¯•:', micResult)

  // æµ‹è¯•è¯­éŸ³è¯†åˆ«
  if (micResult.success) {
    console.log('\nğŸ‘‚ æµ‹è¯•è¯­éŸ³è¯†åˆ«...')
    const recognitionResult = await testSpeechRecognition()
    console.log('è¯­éŸ³è¯†åˆ«æµ‹è¯•:', recognitionResult)
  } else {
    console.log('\nâŒ è·³è¿‡è¯­éŸ³è¯†åˆ«æµ‹è¯• (éº¦å…‹é£æƒé™å¤±è´¥)')
  }

  // æ€»ç»“æŠ¥å‘Š
  const report = {
    capabilities,
    tests: {
      speechSynthesis: synthesisResult,
      microphone: micResult,
      speechRecognition: micResult.success ? await testSpeechRecognition() : { success: false, error: 'éº¦å…‹é£æƒé™ä¸è¶³' }
    },
    recommendations: generateRecommendations(capabilities, synthesisResult, micResult)
  }

  console.log('\nğŸ“‹ å®Œæ•´æµ‹è¯•æŠ¥å‘Š:', report)
  return report
}

/**
 * ç”Ÿæˆä½¿ç”¨å»ºè®®
 */
function generateRecommendations(
  capabilities: VoiceCapabilities, 
  synthesisResult: VoiceTestResult, 
  micResult: VoiceTestResult
): string[] {
  const recommendations: string[] = []

  if (!capabilities.browserInfo.isSecure) {
    recommendations.push('å»ºè®®ä½¿ç”¨HTTPSåè®®ä»¥è·å¾—æœ€ä½³è¯­éŸ³åŠŸèƒ½æ”¯æŒ')
  }

  if (!capabilities.speechRecognition) {
    recommendations.push('å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œå»ºè®®ä½¿ç”¨Chromeã€Edgeæˆ–Safariæœ€æ–°ç‰ˆ')
  }

  if (!capabilities.speechSynthesis) {
    recommendations.push('å½“å‰æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åˆæˆï¼Œå»ºè®®ä½¿ç”¨ç°ä»£æµè§ˆå™¨')
  }

  if (!micResult.success) {
    if (micResult.error?.includes('NotAllowedError') || micResult.error?.includes('Permission denied')) {
      recommendations.push('è¯·å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£æƒé™ï¼Œç„¶ååˆ·æ–°é¡µé¢é‡è¯•')
    } else if (micResult.error?.includes('NotFoundError')) {
      recommendations.push('æœªæ£€æµ‹åˆ°éº¦å…‹é£è®¾å¤‡ï¼Œè¯·ç¡®ä¿éº¦å…‹é£å·²è¿æ¥')
    } else {
      recommendations.push('éº¦å…‹é£è®¿é—®å¤±è´¥ï¼Œè¯·æ£€æŸ¥è®¾å¤‡å’Œæƒé™è®¾ç½®')
    }
  }

  if (capabilities.browserInfo.name === 'Chrome' && parseInt(capabilities.browserInfo.version) < 25) {
    recommendations.push('å»ºè®®å‡çº§Chromeæµè§ˆå™¨è‡³25ç‰ˆæœ¬ä»¥ä¸Šä»¥è·å¾—æ›´å¥½çš„è¯­éŸ³æ”¯æŒ')
  }

  if (capabilities.browserInfo.name === 'Safari' && parseInt(capabilities.browserInfo.version) < 14) {
    recommendations.push('å»ºè®®å‡çº§Safariæµè§ˆå™¨è‡³14.1ç‰ˆæœ¬ä»¥ä¸Šä»¥è·å¾—æ›´å¥½çš„è¯­éŸ³æ”¯æŒ')
  }

  if (recommendations.length === 0) {
    recommendations.push('âœ… æ‚¨çš„æµè§ˆå™¨å®Œå…¨æ”¯æŒè¯­éŸ³åŠŸèƒ½ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨è¯­éŸ³äº¤äº’')
  }

  return recommendations
}

// æ‰©å±•Windowæ¥å£ï¼ˆä½¿ç”¨æ–°çš„å‘½åé¿å…å†²çªï¼‰
declare global {
  interface Window {
    runVoiceTest?: () => Promise<any>
  }
}

// å°†æµ‹è¯•å‡½æ•°æŒ‚è½½åˆ°å…¨å±€ï¼Œæ–¹ä¾¿åœ¨æ§åˆ¶å°è°ƒç”¨
if (typeof window !== 'undefined') {
  window.runVoiceTest = runCompleteVoiceTest
} 